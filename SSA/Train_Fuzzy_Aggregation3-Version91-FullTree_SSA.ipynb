{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T04:34:12.724466Z",
     "start_time": "2020-02-28T04:34:12.713872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"notebook_name = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import Javascript\n",
    "Javascript(\"\"\"\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"notebook_name = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T04:34:12.738055Z",
     "start_time": "2020-02-28T04:34:12.730105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Fuzzy_Aggregation3-Version91-FullTree_SSA\n"
     ]
    }
   ],
   "source": [
    "print(notebook_name)\n",
    "def getFileNumber():\n",
    "    if \"Copy\" not in notebook_name :\n",
    "        return \"1\"\n",
    "    \n",
    "    temp = notebook_name.split(\".\")[0]\n",
    "    temp = temp.split(\"-\")[-1]\n",
    "    temp = temp.replace(\"Copy\",\"\")\n",
    "    return str(int(temp) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T04:34:12.749600Z",
     "start_time": "2020-02-28T04:34:12.741348Z"
    }
   },
   "outputs": [],
   "source": [
    "#13-12-62\n",
    "#Using own file library\n",
    "from ssa_module.ssaC import ssa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T04:34:14.678856Z",
     "start_time": "2020-02-28T04:34:12.752452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "#27-2-63\n",
    "\n",
    "#Using fuzzy fitness \n",
    "#Added send mail\n",
    "#Continue running\n",
    "\n",
    "\n",
    "#https://grega.xyz/post/niapy_optimize_knn/  \n",
    "%autosave 60\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import bisect\n",
    "import math\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Display graph sequently\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "#set_trace()\n",
    "\n",
    "import random\n",
    "import gc\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T04:34:14.696185Z",
     "start_time": "2020-02-28T04:34:14.686399Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert to categorical\n",
    "def to_categorical(val,left_v,right_v) :\n",
    "    if left_v < 0.1 :\n",
    "        left_v = 0.2\n",
    "    if right_v < 0.1 :\n",
    "        right_v = 0.2\n",
    "    output = []\n",
    "    for v in val :\n",
    "        if v < 0.5 :\n",
    "            output.append([left_v,0.1])\n",
    "        else :\n",
    "            output.append([0.1,right_v])\n",
    "    return np.asarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T04:34:14.725568Z",
     "start_time": "2020-02-28T04:34:14.705172Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred,classes,normalize=False,title=None,cmap=plt.cm.Blues):\n",
    "    y_true = np.asarray(y_true).astype('int')\n",
    "    y_pred = np.asarray(y_pred).astype('int')\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    display.display(fig)\n",
    "    plt.close(fig)\n",
    "#     return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controller to show result of Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T04:34:14.796714Z",
     "start_time": "2020-02-28T04:34:14.770955Z"
    }
   },
   "outputs": [],
   "source": [
    "class StoreOptimization(object) :\n",
    "    results = []\n",
    "    generation = 0\n",
    "    \n",
    "    count_generation = 0\n",
    "    \n",
    "    store_best_weights = []\n",
    "    store_best_error = 0\n",
    "    \n",
    "    #default\n",
    "    n_generation_wanted = 1\n",
    "    \n",
    "    store_best_rmse = 1\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def static_N_Gen(val):\n",
    "         StoreOptimization.n_generation_wanted = val\n",
    "    \n",
    "    @staticmethod\n",
    "    def static_clearAll() :\n",
    "        StoreOptimization.generation = 0\n",
    "        StoreOptimization.count_generation = 0\n",
    "        StoreOptimization.store_best_weights = []\n",
    "        StoreOptimization.store_best_error = 100\n",
    "        StoreOptimization.store_best_rmse = 1\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def static_appendString(head_str) :\n",
    "        logging.info('%s' % (head_str))\n",
    "        print('%s' % (head_str))\n",
    "    \n",
    "    @staticmethod\n",
    "    def static_addResult(Pc1,Pc2,Pc,fuzzy_fitness,weights,n_fold,rmse_eval) :\n",
    "        \n",
    "            \n",
    "        StoreOptimization.count_generation = StoreOptimization.count_generation + 1\n",
    "        StoreOptimization.generation = StoreOptimization.generation + 1\n",
    "        \n",
    "        if StoreOptimization.n_generation_wanted == StoreOptimization.count_generation :\n",
    "            StoreOptimization.count_generation = 0\n",
    "            StoreOptimization.static_appendString('fold %s nFES %s error %s' % (n_fold,StoreOptimization.generation, rmse_eval))\n",
    "        \n",
    "        if fuzzy_fitness < StoreOptimization.store_best_error :\n",
    "            StoreOptimization.store_best_error = fuzzy_fitness\n",
    "            StoreOptimization.store_best_weights = weights\n",
    "            StoreOptimization.static_appendString('fold %s best at nFES %s error %s (%s,%s,%s) rmse %s' % (n_fold,StoreOptimization.generation, fuzzy_fitness,Pc1,Pc2,Pc,rmse_eval))\n",
    "            logging.info(weights)\n",
    "\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.676Z"
    }
   },
   "outputs": [],
   "source": [
    "class leaf_node :\n",
    "    def __init__(self,count_leaves) :\n",
    "        self.list_weight_input = np.ones(count_leaves).tolist()\n",
    "        self.gammar_operator = 1.0\n",
    "        \n",
    "    def check_input(self,val) :\n",
    "        '''\n",
    "        Axiom 1\n",
    "        Check input h(0,0,0) = 0\n",
    "        Check input h(1,1,1) = 1\n",
    "        '''\n",
    "        repeat_zeros = np.repeat(0.00000001,len(val))\n",
    "        repeat_ones = np.repeat(0.99999999,len(val))\n",
    "        \n",
    "        if np.sum(val == repeat_zeros) == len(val) :\n",
    "            return np.repeat(0.0,len(val)).tolist()\n",
    "        \n",
    "        if np.sum(val == repeat_ones) == len(val) :\n",
    "            return np.repeat(1.0,len(val)).tolist()\n",
    "            \n",
    "        return val\n",
    "        \n",
    "        \n",
    "    def cal_y(self,input_x) :\n",
    "        \n",
    "        input_x = self.check_input(input_x)\n",
    "         \n",
    "        if len(input_x) != len(self.list_weight_input) :\n",
    "            print(\"Error cal , input not equal weight\")\n",
    "            return\n",
    "    \n",
    "        \n",
    "        temp_mul_y1 = [ np.power(input_x[idx] , self.list_weight_input[idx]) for idx in range(0,len(input_x)) ]\n",
    "        \n",
    "        prod_y1 = 1\n",
    "        for idx in  temp_mul_y1  :\n",
    "            prod_y1 = prod_y1 * idx\n",
    "            \n",
    "        y1_out = np.power(prod_y1,1-self.gammar_operator)\n",
    "        \n",
    "        temp_mul_y2 = [ np.power(1-input_x[idx],self.list_weight_input[idx]) for idx in range(0,len(input_x)) ]\n",
    "        \n",
    "        prod_y2 = 1\n",
    "        for idx in  temp_mul_y2  :\n",
    "            prod_y2 = prod_y2 * idx\n",
    "            \n",
    "        y2_out = np.power(1 - prod_y2,self.gammar_operator)\n",
    "        \n",
    "        real_out = y1_out * y2_out\n",
    "         \n",
    "        if real_out == 0 :\n",
    "            real_out = 0.00000001\n",
    "        elif real_out == 1 :\n",
    "            real_out = 0.99999999\n",
    "            \n",
    "        return real_out\n",
    "\n",
    "    def change_weights(self,new_weight,new_gammar) :\n",
    "\n",
    "        if self.count_weight() == len(new_weight) :\n",
    "            self.list_weight_input = new_weight\n",
    "            self.gammar_operator = new_gammar\n",
    "\n",
    "        else :\n",
    "            print(\"Error Update weight!!!!!\")\n",
    "            raise\n",
    "            \n",
    "    def count_weight(self) :\n",
    "        return len(self.list_weight_input)\n",
    "    \n",
    "    def get_weights_gammar(self) :\n",
    "        return self.list_weight_input + [self.gammar_operator]\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.680Z"
    }
   },
   "outputs": [],
   "source": [
    "class root_tree :\n",
    "    \n",
    "    def __init__(self,list_group) :\n",
    "        self.number_layers = len(list_group)\n",
    "        self.all_nodes = []\n",
    "        \n",
    "\n",
    "        #Leaf (Top) -> Root (Bottom)\n",
    "        \n",
    "        for count_layer in range(0,len(list_group)) :\n",
    "            temp_leaves = []\n",
    "            for count_node in  range(0,len(list_group[count_layer])) :\n",
    "                temp_leaves.append(leaf_node(list_group[count_layer][count_node]))\n",
    "            self.all_nodes.append(temp_leaves)\n",
    "            \n",
    "        #Split vector input to input each group\n",
    "        self.group_input = list_group\n",
    "\n",
    "    \n",
    "    def get_all_weights_wGammar(self) :\n",
    "        #Return weight and gammar all tree to vector\n",
    "        output = []\n",
    "    \n",
    "        for each_layer in self.all_nodes :\n",
    "            for each_node in each_layer :\n",
    "                \n",
    "                #New position vector X\n",
    "                output = output+each_node.get_weights_gammar()\n",
    "            \n",
    "        return output\n",
    "                \n",
    "    def set_all_weights_wGammar(self,new_weights) :\n",
    "        count_weight_idx = 0\n",
    "        \n",
    "        for each_layer in self.all_nodes :\n",
    "            for each_node in each_layer :\n",
    "                \n",
    "                len_weight = each_node.count_weight()\n",
    "                temp_weights = new_weights[count_weight_idx:count_weight_idx + len_weight]\n",
    "                temp_gammar = new_weights[count_weight_idx+len_weight]\n",
    "                \n",
    "                \n",
    "                #Change weights\n",
    "                try : \n",
    "                    each_node.change_weights(temp_weights,temp_gammar)\n",
    "                except :\n",
    "                    print(\"Error change weight !\")\n",
    "                    sys.exit()\n",
    "                \n",
    "                #New position\n",
    "                count_weight_idx = count_weight_idx+len_weight+1\n",
    "        \n",
    "        \n",
    "                \n",
    "          \n",
    "    #For multi objective to find error\n",
    "    def predict_eachLeaf(self,input_X) :\n",
    "        \n",
    "        summation_error = 0\n",
    "        \n",
    "        output_previous_layer = input_X\n",
    "        \n",
    "        summation_resultY = []\n",
    "        \n",
    "        #feed only leaves tree \n",
    "        for idx,each_layer in enumerate(self.all_nodes) :\n",
    "\n",
    "            count_idx = 0\n",
    "            temp_previous_result = []\n",
    "            \n",
    "            if idx != len(self.all_nodes) - 1 :\n",
    "            \n",
    "                for each_node in each_layer :\n",
    "\n",
    "                    input_x_vector = output_previous_layer[count_idx:count_idx + each_node.count_weight()]\n",
    "\n",
    "                    resultFrom_calY = each_node.cal_y(input_x_vector)\n",
    "\n",
    "                    summation_resultY =  summation_resultY + [resultFrom_calY]\n",
    "\n",
    "                    temp_previous_result.append(resultFrom_calY)\n",
    "\n",
    "                    #New position vector X\n",
    "                    count_idx = count_idx+each_node.count_weight()\n",
    "            else :\n",
    "                \n",
    "                #Get old output from previous cal and calculate two output to classify\n",
    "        \n",
    "                temp_output2class = []\n",
    "                for each_node in each_layer :\n",
    "                    input_x_vector = output_previous_layer[0:count_idx + each_node.count_weight()]\n",
    " \n",
    "                    resultFrom_calY = each_node.cal_y(input_x_vector)\n",
    "                    temp_output2class.append(resultFrom_calY)\n",
    "\n",
    "                summation_resultY =  summation_resultY + temp_output2class\n",
    " \n",
    "            output_previous_layer =  temp_previous_result\n",
    "\n",
    "        return summation_resultY\n",
    "    \n",
    "    \n",
    "    #Feed input to get output only\n",
    "    def predict(self,input_X) :\n",
    "        temp = self.predict_eachLeaf(input_X)[-2::1]\n",
    "        if (temp[0] == 0 and temp[1] == 0) or np.isinf(temp[0]) or np.isinf(temp[1]) or np.isnan(temp[0]) or np.isnan(temp[1]) :\n",
    "            temp = self.predict_eachLeaf(input_X)[-2::1]\n",
    "        return temp\n",
    "        \n",
    "    \n",
    "    def readable(self) :\n",
    "        #Return weight and gammar all tree to vector\n",
    "        temp = []\n",
    "        for (idx,each_layer) in enumerate(self.all_nodes) :\n",
    "            temp = []\n",
    "            for (i,each_node) in enumerate(each_layer) :\n",
    "                temp_get_weight = each_node.get_weights_gammar()\n",
    "                print(\"Weight layer \",idx,\":\",i+1,\" \",temp_get_weight[0:-1])\n",
    "                print(\"Gammar operator : \",temp_get_weight[-1])\n",
    "                print(\"Sum Weights : \",np.sum(temp_get_weight[:-1]))\n",
    "                print(\"\")\n",
    "                #Show important weight each group ratios at final step\n",
    "                \n",
    "                temp.append(temp_get_weight)\n",
    "        \n",
    "            print(\"For check sum at layer: \",np.sum([np.sum(x[0:-1]) for x in temp]))\n",
    "            print(\"\")\n",
    "                \n",
    "        print(\"\")\n",
    "        print(\"#### Left output node ####\")\n",
    "        print(\"liquidity ratio : \",temp[0][0])\n",
    "        print(\"Asset utilization or turnover ratio : \",temp[0][1])\n",
    "        print(\"Profitability : \",temp[0][2])\n",
    "        print(\"Gammar operator : \",temp[0][3])\n",
    "        print(\"Leverage : \",temp[0][4])\n",
    "        print(\"Growth ratios : \",temp[0][5])\n",
    "        print(\"Gammar operator : \",temp[0][6])\n",
    "        print(\"For check sum : \",np.sum(temp[0]) - temp[0][-1])\n",
    "        print(\"\")\n",
    "        print(\"#### Right output node ####\")\n",
    "        print(\"liquidity ratio : \",temp[1][0])\n",
    "        print(\"Asset utilization or turnover ratio : \",temp[1][1])\n",
    "        print(\"Profitability : \",temp[1][2])\n",
    "        print(\"Asset structure ratios : \",temp[1][3])\n",
    "        print(\"Leverage : \",temp[1][4])\n",
    "        print(\"Growth ratios : \",temp[1][5])\n",
    "        print(\"Gammar operator : \",temp[1][6])\n",
    "        print(\"For check sum : \",np.sum(temp[1])-temp[1][-1])\n",
    "    \n",
    "    def countAllNodesOutput(self) :\n",
    "        output = 0\n",
    "        for count_layer in self.group_input :\n",
    "            output = output + len(count_layer)\n",
    "        return output\n",
    "                \n",
    "\n",
    "    \n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.683Z"
    }
   },
   "outputs": [],
   "source": [
    "def try_div(x,y):\n",
    "    try: \n",
    "        return x/y\n",
    "    except ZeroDivisionError: \n",
    "        return 0\n",
    "\n",
    "    \n",
    "def swap_gammar(val) :\n",
    "    if math.isnan(val) :\n",
    "        return 0\n",
    "    return val\n",
    "\n",
    "    \n",
    "def swap_weight(val) :\n",
    "    len_weight = len(val)\n",
    "    temp_multiply =  try_div(len_weight,np.sum(val))\n",
    "    if math.isnan(temp_multiply) or temp_multiply == 0 :\n",
    "        temp_multiply = 1\n",
    "        \n",
    "    output = (temp_multiply * np.asarray(val)).tolist()\n",
    "    output = [0 if math.isnan(x) else x for x in output]\n",
    "\n",
    "    return output\n",
    "\n",
    "# our custom benchmark classs\n",
    "class BenchmarkAllTree(object):\n",
    "    def __init__(self,tree_shape,start_pos_f,end_pos_f,n_fold):\n",
    "        # define lower bound of benchmark function\n",
    "        self.Lower = 0\n",
    "        # define upper bound of benchmark function\n",
    "        self.Upper = 1\n",
    "        \n",
    "        self.tree_shape = tree_shape\n",
    "        \n",
    "        self.start_pos_f = start_pos_f\n",
    "        self.end_pos_f = end_pos_f\n",
    "        \n",
    "        self.n_fold = n_fold\n",
    "        \n",
    "        self.fuzzy_system = fuzzy_aggregation(tree_shape = self.tree_shape,current_fold_train=n_fold)\n",
    "        \n",
    "        \n",
    "\n",
    "    # function which returns evaluate function\n",
    "    def evaluate(self,sol):\n",
    "        sol = np.abs(sol)\n",
    "        \n",
    "        all_weight = []\n",
    "\n",
    "        last_idx = 0\n",
    "\n",
    "\n",
    "        for idx,each_layer in enumerate(self.tree_shape) :\n",
    "\n",
    "            if idx == len(self.tree_shape) -1 :\n",
    "\n",
    "                    for each_node in each_layer :\n",
    "                        #find weights and gamma before\n",
    "\n",
    "                        len_each_layer_weights = each_node\n",
    "                        len_each_layer_gammas = len(each_layer)\n",
    "\n",
    "                        temp_pos_next_weights = last_idx + len_each_layer_weights\n",
    "\n",
    "\n",
    "                        temp_vector_weights = swap_weight(sol[last_idx:temp_pos_next_weights])\n",
    "                        temp_vector_gammars = sol[temp_pos_next_weights : temp_pos_next_weights + len_each_layer_gammas]\n",
    "\n",
    "                        temp_idx_w = 0\n",
    "                        temp_idx_g = 0\n",
    "\n",
    "\n",
    "                        all_weight = all_weight + temp_vector_weights[temp_idx_w:temp_idx_w + each_node] + [temp_vector_gammars[temp_idx_g]]\n",
    "                        temp_idx_w = temp_idx_w + each_node\n",
    "                        temp_idx_g = temp_idx_g + 1\n",
    "                        last_idx = last_idx + each_node + 1\n",
    "\n",
    "            else :\n",
    "                #find weights and gamma before\n",
    "                    for each_node in each_layer :\n",
    "                        temp_weights = swap_weight(sol[last_idx:last_idx + each_node])\n",
    "                        temp_gammar = swap_gammar(sol[last_idx + each_node])\n",
    "                        last_idx = last_idx + each_node + 1\n",
    "                        all_weight = all_weight + temp_weights + [temp_gammar]\n",
    "\n",
    "        gc.collect()\n",
    "        set_eval = self.fuzzy_system.evaluate(all_weight,self.start_pos_f ,self.end_pos_f)\n",
    "        StoreOptimization.static_addResult(set_eval[1],set_eval[4],set_eval[0],set_eval[-1][0],all_weight,self.n_fold,set_eval[-1][1])\n",
    "\n",
    "        if math.isnan(set_eval[-1][0]) :\n",
    "            set_trace()\n",
    "\n",
    "        return set_eval[-1][0]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.687Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class fuzzy_aggregation :\n",
    "    def __init__(self,tree_shape, seed=1235,current_fold_train=1,ignore_writeClass=False) :\n",
    "        self.classifier_root_tree = root_tree(tree_shape)\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.current_fold_train = current_fold_train\n",
    "        global crossvalidation\n",
    "        self.crossvalidation = crossvalidation\n",
    "        \n",
    "        global number_feature\n",
    "        self.number_feature = number_feature\n",
    "        self.all_shape = tree_shape \n",
    "        \n",
    "        global all_data_train\n",
    "        self.all_data_train = all_data_train\n",
    "\n",
    "        random.seed(self.seed)\n",
    "        idx = random.sample(range(0, len(self.all_data_train.index)), len(self.all_data_train.index))\n",
    "\n",
    "\n",
    "#         self.data_train,self.data_blindtest = self.split_blind_test(data_train=np.asarray(self.all_data_train)[idx,:])\n",
    "        self.data_train =np.asarray(self.all_data_train)[idx,:]\n",
    "        \n",
    "        temp_X_train,temp_X_test = self.select_fold(self.current_fold_train)\n",
    "        \n",
    "        #Var for used\n",
    "        self.X_train,self.y_train = self.split_features_class(temp_X_train)\n",
    "        self.X_test,self.y_test = self.split_features_class(temp_X_test)\n",
    "        \n",
    "        \n",
    "#         self.X_blindtest,self.y_blindtest = self.split_features_class(self.data_blindtest)\n",
    "\n",
    "        print(\"Y Train count abnormal : \",len(self.y_train[self.y_train == 1]))\n",
    "        print(np.sum(self.y_train==1) ,len(self.y_train))\n",
    "        print(np.sum(self.y_train==0) ,len(self.y_train))\n",
    "        #set wight output\n",
    "        self.weight_classOne = 1 - (np.sum(self.y_train==1) / len(self.y_train))\n",
    "        self.weight_classZero = 1 - (np.sum(self.y_train==0) / len(self.y_train))\n",
    "        \n",
    "       \n",
    "        self.y_real_train_category = to_categorical(self.y_train,self.weight_classZero,self.weight_classOne)\n",
    "        self.y_real_test_category = to_categorical(self.y_test,self.weight_classZero,self.weight_classOne)\n",
    "        \n",
    "        if not ignore_writeClass :\n",
    "            allWeightOutput = to_categorical([0,1],self.weight_classZero,self.weight_classOne)\n",
    "            StoreOptimization.static_appendString(\"## parameter weight output class zero [%s,%s] \" % (allWeightOutput[0][0],allWeightOutput[0][1]))\n",
    "            StoreOptimization.static_appendString(\"## parameter weight output class one [%s,%s] \" % (allWeightOutput[1][0],allWeightOutput[1][1]))\n",
    "            del allWeightOutput\n",
    "        \n",
    "    def split_blind_test(self,test_size=0.8,data_train = []) :\n",
    "    \n",
    "        range_split= math.floor(len(data_train)*test_size)\n",
    "        return data_train[0:range_split,:], data_train[range_split:,:]\n",
    "    \n",
    "    def select_fold(self,number_fold):\n",
    "        #return train,test\n",
    "\n",
    "        range_v = math.floor(len(self.data_train)/self.crossvalidation)\n",
    "        if number_fold == 1 :\n",
    "            return self.data_train[range_v:,:] , self.data_train[0:range_v,:] \n",
    "        elif number_fold == self.crossvalidation :\n",
    "            return self.data_train[0:range_v*(number_fold-1),:], self.data_train[range_v*(number_fold-1):,:] \n",
    "        else :\n",
    "            temp_data_first = self.data_train[0:range_v*(number_fold-1),:]\n",
    "\n",
    "            temp_data_second = self.data_train[range_v*(number_fold):,:]\n",
    "            final_con = np.concatenate((temp_data_first, temp_data_second))\n",
    "            return final_con , self.data_train[range_v*(number_fold-1):range_v*(number_fold),:]\n",
    "    \n",
    "    def split_features_class(self,v_input) :\n",
    "        #Vector feature , Vector class\n",
    "        return v_input[:,0:self.number_feature],v_input[:,-1]\n",
    "    \n",
    "    def calculate_RMSE(self,y_real,y_predict) :\n",
    "        if len(y_predict) != len(y_real) :\n",
    "            print(\"Cannot calculate RMSE\")\n",
    "            sys.exit()\n",
    "\n",
    "        temp_minus = y_real - y_predict\n",
    "        \n",
    "\n",
    "        error_all = []\n",
    "        for y in temp_minus :\n",
    "            error_all.append((y[0]*y[0] + y[1]*y[1])/2)\n",
    "        \n",
    "        return math.sqrt(np.sum(error_all)/len(error_all))\n",
    "\n",
    "    def predict(self,start_f_in,end_f_in) :\n",
    "       \n",
    "        return [ self.classifier_root_tree.predict( self.X_train[idx,start_f_in:end_f_in+1] ) for idx in range(self.X_train.shape[0]) ]\n",
    "        \n",
    "    '''\n",
    "        Product T-Norm (AND)\n",
    "        Product T-Conorm (OR)\n",
    "        \n",
    "        Min (Max(class1,class2) , Accuracy)\n",
    "        (class_x + class_y - class_x . class_y) . Accuracy\n",
    "        \n",
    "    '''\n",
    "    def fuzzy_fitness_wRMSE(self,y_real,y_predict):\n",
    "        if len(y_predict) != len(y_real) :\n",
    "            print(\"Cannot calculate fuzzy fitness\")\n",
    "            sys.exit()\n",
    "\n",
    "        temp_minus = y_real - y_predict\n",
    "        \n",
    "        \n",
    "        class_1 = []\n",
    "        class_2 = []\n",
    "\n",
    "        error_all = []\n",
    "        for y,y_r,y_p in zip(temp_minus, y_real, y_predict) :\n",
    "            if y_r[0] == 1 :\n",
    "                class_1.append((y[0]*y[0] + y[1]*y[1])/2)\n",
    "            else :\n",
    "                class_2.append((y[0]*y[0] + y[1]*y[1])/2)\n",
    "            error_all.append((y[0]*y[0] + y[1]*y[1])/2)\n",
    "            \n",
    "        if len(error_all) != 0:\n",
    "            sum_sqrt = np.sqrt(sum(error_all)/len(error_all))\n",
    "        else :\n",
    "            sum_sqrt = 0\n",
    "        if len(class_1) != 0 :\n",
    "            sum_class1 = np.sqrt(sum(class_1)/len(class_1))\n",
    "        else :\n",
    "            sum_class1 = 0\n",
    "        if len(class_2) != 0 :\n",
    "            sum_class2 = np.sqrt(sum(class_2)/len(class_2))\n",
    "        else :\n",
    "            sum_class2 = 0\n",
    "        \n",
    "        return ((sum_class1 +sum_class2 ) - (sum_class1*sum_class2)) * sum_sqrt , math.sqrt(np.sum(error_all)/len(error_all))\n",
    "        \n",
    "        \n",
    "    def evaluate(self,weight_gammar,start_f_in,end_f_in,show_graph=False) :\n",
    "        \n",
    "        self.classifier_root_tree.set_all_weights_wGammar(weight_gammar)\n",
    "        y_prediction = self.predict(start_f_in,end_f_in)\n",
    "        \n",
    "        \n",
    "        y_binary_prediction = []\n",
    "        for y in y_prediction :\n",
    "            \n",
    "            #[0,1] class 1\n",
    "            if y[0] < y[1] :\n",
    "                y_binary_prediction.append(1)\n",
    "            else :\n",
    "                #[0,1] class 1\n",
    "                y_binary_prediction.append(0)\n",
    "                \n",
    "        #Root mean squared error (RMSE)\n",
    "#         return self.accuracy_cal(self.y_train,y_binary_prediction),self.calculate_RMSE(self.y_train,y_prediction)\n",
    "        tn, fp, fn, tp = confusion_matrix(self.y_train,y_binary_prediction).ravel()\n",
    "        acc_train = self.accuracy_cal(self.y_train,y_binary_prediction,show_graph=show_graph)\n",
    "\n",
    "        return  [acc_train,tn, fp, fn, tp,self.fuzzy_fitness_wRMSE(self.y_real_train_category,y_prediction)]\n",
    "    \n",
    "    def predict_validateTest(self,start_f_in,end_f_in) :\n",
    "        return [ self.classifier_root_tree.predict( self.X_test[idx,start_f_in:end_f_in+1]  ) for idx in range(self.X_test.shape[0]) ]\n",
    "        \n",
    "    \n",
    "    def validate_test(self,weight_gammar,start_f_in,end_f_in,show_graph=False) :\n",
    "        self.classifier_root_tree.set_all_weights_wGammar(weight_gammar)\n",
    "        \n",
    "        y_prediction = self.predict_validateTest(start_f_in,end_f_in)\n",
    "\n",
    "        y_binary_prediction = []\n",
    "        for y in y_prediction :\n",
    "            #[0,1] class 1\n",
    "            if y[0] < y[1] :\n",
    "                y_binary_prediction.append(1)\n",
    "            else :\n",
    "                #[0,1] class 1\n",
    "                y_binary_prediction.append(0)\n",
    "                \n",
    "        return self.accuracy_cal(self.y_test,y_binary_prediction,show_graph=show_graph),self.fuzzy_fitness_wRMSE(self.y_real_test_category,y_prediction)\n",
    "    \n",
    "#     def predict_blindtest(self,start_f_in,end_f_in) :\n",
    "#         return [ self.classifier_root_tree.predict( self.X_blindtest[idx,start_f_in:end_f_in+1]  ) for idx in range(self.X_blindtest.shape[0]) ]\n",
    "        \n",
    "    \n",
    "#     def blind_test(self,weight_gammar,start_f_in,end_f_in) :\n",
    "#         self.classifier_root_tree.set_all_weights_wGammar(weight_gammar)\n",
    "        \n",
    "#         y_prediction = self.predict_blindtest(start_f_in,end_f_in)\n",
    "        \n",
    "#         return self.accuracy_cal(self.y_blindtest,y_prediction),self.calculate_RMSE(self.y_blindtest,y_prediction)\n",
    "    \n",
    "    def calculate_evaluate_model(self,result_wanted_y,y_prediction,y_categorical) :\n",
    "        error_all = []\n",
    "        \n",
    "        y_binary_prediction = []\n",
    "        for (y1,y2) in zip(y_prediction,y_categorical) :\n",
    "            print(\"Predict %s , Actual %s \" % (\"[\" + str( y1[0]) +\",\"+ str(y1[1]) + \"]\",y2))\n",
    "            error_all.append(np.abs(np.sum(y1-y2)/2))\n",
    "            #[1,0] class 0\n",
    "            if  y1[0] < y1[1] :\n",
    "                y_binary_prediction.append(1)\n",
    "            else :\n",
    "                #[0,1] class 1\n",
    "                y_binary_prediction.append(0)\n",
    "            \n",
    "        print(\"MAE = \",np.sum(error_all)/len(error_all))\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(result_wanted_y,y_binary_prediction).ravel()\n",
    "        print(\"\\t-----------\\t \\t-----------\\t\")\n",
    "        print(\"|\\t tn - %s \\t|,|\\t fp - %s \\t|\" % (tn, fp))\n",
    "        print(\"|\\t fn - %s \\t|,|\\t tp - %s \\t|\" % (fn, tp))\n",
    "        print(\"\\t-----------\\t \\t-----------\\t\")\n",
    "        acc = accuracy_score( result_wanted_y,y_binary_prediction)\n",
    "        f1 = self.f1_cal(result_wanted_y, y_binary_prediction)\n",
    "\n",
    "        print(\"Acc = %s , f1 = %s\" % (acc,f1))\n",
    "        print(\"RMSE = \",self.calculate_RMSE(y_categorical,y_prediction))\n",
    "        print(\"Fuzzy Fitness = \",self.fuzzy_fitness_wRMSE(y_categorical,y_prediction)[0])\n",
    "        \n",
    "        \n",
    "        plot_confusion_matrix(result_wanted_y, y_binary_prediction,classes = np.asarray(['normal', 'Signed']) )\n",
    "      \n",
    "        \n",
    "    def print_results(self,weight_gammar,start_f_in,end_f_in) :\n",
    "        self.classifier_root_tree.set_all_weights_wGammar(weight_gammar)\n",
    "\n",
    "        #Config\n",
    "        result_wanted_y = self.y_test\n",
    "        result_wanted_X = self.X_test\n",
    "        \n",
    "        y_prediction = [ self.classifier_root_tree.predict( result_wanted_X[idx,start_f_in:end_f_in+1]  ) for idx in range(result_wanted_X.shape[0]) ]\n",
    "        \n",
    "        self.calculate_evaluate_model(result_wanted_y,y_prediction,self.y_real_test_category)\n",
    "    \n",
    "    def print_results_train(self,weight_gammar,start_f_in,end_f_in) :\n",
    "        self.classifier_root_tree.set_all_weights_wGammar(weight_gammar)\n",
    "\n",
    "        #Config\n",
    "        result_wanted_y = self.y_train\n",
    "        result_wanted_X = self.X_train\n",
    "        \n",
    "        y_prediction = [ self.classifier_root_tree.predict( result_wanted_X[idx,start_f_in:end_f_in+1]  ) for idx in range(result_wanted_X.shape[0]) ]\n",
    "        \n",
    "        self.calculate_evaluate_model(result_wanted_y,y_prediction,self.y_real_train_category)\n",
    "\n",
    "    def set_allWeights(self,new_weight) :\n",
    "        self.classifier_root_tree.set_all_weights_wGammar(new_weight)\n",
    "        \n",
    "    def showAllWeights(self) :\n",
    "        self.classifier_root_tree.readable()\n",
    "    \n",
    "    def accuracy_cal(self,y_real,y_predict,show_graph=False) :\n",
    "        \n",
    "        acc = accuracy_score( y_real,y_predict)\n",
    "        if show_graph == True :\n",
    "            plot_confusion_matrix( y_real,y_predict,classes = np.asarray(['normal', 'Signed']) )\n",
    "        \n",
    "        return acc\n",
    "        \n",
    "    def f1_cal(self,y_real,y_predict) :\n",
    "        f_score = f1_score(y_real,y_predict,average='weighted')\n",
    "        \n",
    "        return f_score\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.690Z"
    }
   },
   "outputs": [],
   "source": [
    "# logger = logging.getLogger()\n",
    "# fhandler = logging.FileHandler(filename='log_train_opt.log')\n",
    "# formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "# fhandler.setFormatter(formatter)\n",
    "# logger.addHandler(fhandler)\n",
    "# logger.setLevel(logging.INFO)\n",
    "import datetime \n",
    "class logging(object) :\n",
    "    \n",
    "    file_name = \"log_train_Finan_1.log\"\n",
    "    \n",
    "    def initial(file_name):\n",
    "        logging.file_name = file_name\n",
    "    \n",
    "    @staticmethod\n",
    "    def info(msg) :\n",
    "        f = open(logging.file_name, \"a+\")\n",
    "        f.write(\"%s - %s \\n\" % (datetime.datetime.now(),msg) )\n",
    "        f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.692Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "get params from previous fold in case of training not finished\n",
    "'''\n",
    "import ast\n",
    "def loadDataFromPreviousFold(name_previous_fold):\n",
    "    global best_sol_cross, acc_cross, error_cross, best_fold, best_cross_train_err, best_acc_train,best_rmse_train,best_rmse_test\n",
    "\n",
    "    if best_sol_cross != [] :\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        tmp = list(reversed(open(name_previous_fold).readlines()))\n",
    "    except:\n",
    "        print(\"Error cannot continue train from fold 1\")\n",
    "        raise\n",
    "\n",
    "    best_rmse_test = float(tmp[0].rstrip().split(\"** Best RMSE Validate now = \")[1])\n",
    "    acc_cross = float(tmp[1].rstrip().split(\"** Best Accuracy Validate now = \")[1])\n",
    "    error_cross = float(tmp[2].rstrip().split(\"** Best validation error now = \")[1])\n",
    "    best_rmse_train = float(tmp[3].rstrip().split(\"** Best RMSE Train now = \")[1])\n",
    "    best_acc_train = float(tmp[4].rstrip().split(\"** Best Accuracy Train now = \")[1])\n",
    "    best_cross_train_err = float(tmp[5].rstrip().split(\"** Best Train now = \")[1])\n",
    "    best_fold = int(tmp[6].rstrip().split(\"** Best n_Fold now = \")[1])\n",
    "    best_sol_cross = ast.literal_eval(tmp[7].rstrip().split(\"** Best Weights now = \")[1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.695Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import SwarmPackagePy\n",
    "\n",
    "def count_weight_from_tree(shape_OfTree):\n",
    "    count_weight = 0\n",
    "    for each_layer in shape_OfTree :\n",
    "        list_all_weight_gammar = [ w + 1 for w in each_layer ]\n",
    "        count_weight = count_weight + np.sum(list_all_weight_gammar)\n",
    "\n",
    "    return count_weight\n",
    "\n",
    "# tree_shape = [[8,8,8,8,8,8,8,8],[2,3,3],[2,1],[2]]\n",
    "tree_shape = [[8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8],\n",
    "              [3,2,2,4,4,2,1,4,2,1,2,2,5,1,1,2],\n",
    "              [2,5,3,2,2,2],[6,6]]\n",
    "n_weight_gammar = count_weight_from_tree(tree_shape) \n",
    "\n",
    "try :\n",
    "    name_file_train = \"./Final_Data_Train_8_MultiNC.csv\"\n",
    "    all_data_train = pd.read_csv(name_file_train,index_col=\"index_firm\")\n",
    "except :\n",
    "    name_file_train = \"../Final_Data_Train_8_MultiNC.csv\"\n",
    "    all_data_train = pd.read_csv(name_file_train,index_col=\"index_firm\")\n",
    "    \n",
    "for col in all_data_train.columns[:-1]:\n",
    "    all_data_train[col] = [x if x > 0 else 0.00000001 for x in all_data_train[col]]\n",
    "    all_data_train[col] = [x if x < 1 else 0.99999999 for x in all_data_train[col]]\n",
    "\n",
    "\n",
    "\n",
    "## Arrange columns ##\n",
    "list_ratio = [\"CR\",\"QR\",\"CashR\",\"CA2NA\",\"NWC2TA\"]\n",
    "list_ratio = list_ratio + [\"ART\",\"ACP\",\"ITR\",\"ASP\",\"FA2NW\",\"FAT\",\"NWCTR\",\"TAT\",\"ETR\",\"CA2TR\",\"APT\",\"APP\",\"CC\"]\n",
    "list_ratio = list_ratio + [\"ROA\",\"GPM\",\"NPM\",\"ROE\",\"P2NWC\",\"ROS\",\"OE2NS\"]\n",
    "list_ratio = list_ratio + [\"CA2TA\",\"LA2TA\",\"I2CA\",\"CCE2CA\"]\n",
    "list_ratio = list_ratio + [\"D2TAR\",\"D2E\",\"TL2NW\",\"STD2TD\",\"ICR\",\"RE2S\"]\n",
    "list_ratio = list_ratio + [\"AGR\",\"SGR\",\"NPGR\"]\n",
    "new_name_columns = []\n",
    "for idx , val in enumerate(list_ratio) :\n",
    "    for i in range(0,tree_shape[0][0]) :\n",
    "        new_name_columns.append(list_ratio[idx] + \"-Last\" + str(i))\n",
    "new_name_columns = new_name_columns + [\"class\"]\n",
    "\n",
    "all_data_train = all_data_train[new_name_columns]\n",
    "\n",
    "\n",
    "##### Columns drop #######\n",
    "# columns_drop = []\n",
    "# for ratio in [\"TAT\",\"R2NWC\",\"RE2S\",\"S2NW\",\"emscore\",\"CR\",\"QR\"] :\n",
    "#     for idx in range(0,8) :\n",
    "#         columns_drop = columns_drop + [ratio+\"-Last\"+str(idx)]\n",
    "\n",
    "# all_data_train = all_data_train.drop(columns_drop, axis=1)\n",
    "\n",
    "##################### Store Best fold #########################\n",
    "\n",
    "best_sol_cross = []\n",
    "acc_cross = 0\n",
    "error_cross = 0\n",
    "best_fold = 1\n",
    "best_cross_train_err = 0\n",
    "best_acc_train = 0\n",
    "\n",
    "\n",
    "############## Start & End pos feature #######################\n",
    "pos_start = 0\n",
    "pos_end =len(all_data_train.columns)-2\n",
    "\n",
    "\n",
    "\n",
    "################# In Aggregation algor ##################\n",
    "number_feature = pos_end + 1\n",
    "crossvalidation = 2\n",
    "\n",
    "\n",
    "############### Config Params ###############\n",
    "\n",
    "train_params = {}\n",
    "train_params[\"NP\"] = 3000\n",
    "\n",
    "#Gen\n",
    "train_params[\"nIteration\"] = 40\n",
    "\n",
    "train_params[\"lb\"] = 0\n",
    "train_params[\"ub\"] = 1\n",
    "\n",
    "train_params[\"dimension\"] = n_weight_gammar\n",
    "\n",
    "\n",
    "#SSA\n",
    "train_params[\"pf\"] = 0.6\n",
    "\n",
    "\n",
    "# 'D' = D {array} or {int} – Shape of return random numbers \n",
    "name_file_fold1 = \"log_t_f_38s_8Q_SSA_\"+getFileNumber()+\"_fold1.log\"\n",
    "name_file_fold2 = \"log_t_f_38s_8Q_SSA_\"+getFileNumber()+\"_fold2.log\"\n",
    "\n",
    "def trainWithFold(nFold,nameSaveFile) :\n",
    "    global best_sol_cross,acc_cross,error_cross,best_fold,best_cross_train,best_acc_train,name_file_train\n",
    "    \n",
    "    logging.initial(nameSaveFile)\n",
    "    StoreOptimization.static_appendString(\"You're going to train with file \" + name_file_train + \" & Saved = \"+logging.file_name)\n",
    "\n",
    "    n_fold = nFold\n",
    "    \n",
    "    #nGEN , nFES\n",
    "    StoreOptimization.static_clearAll()\n",
    "    StoreOptimization.static_N_Gen(1000)\n",
    "    \n",
    "   #Create evaluate fn\n",
    "    eval = BenchmarkAllTree(tree_shape,pos_start,pos_end,n_fold) \n",
    "\n",
    "    #SSA\n",
    "    StoreOptimization.static_appendString(\"## New training SSA with n = %s , lb = %s , ub = %s, dimension = %s, iteration = %s, pf= %s with fold = %s \" % (train_params[\"NP\"] , train_params[\"lb\"], train_params[\"ub\"], train_params[\"dimension\"], train_params[\"nIteration\"], train_params[\"pf\"],n_fold))\n",
    "    algor = ssa(train_params[\"NP\"] , eval.evaluate, train_params[\"lb\"], train_params[\"ub\"], train_params[\"dimension\"], train_params[\"nIteration\"], pf=train_params[\"pf\"])\n",
    "\n",
    "    \n",
    "    print(\"Optimal Weight and Gammar are : \")  \n",
    "    best_solution = StoreOptimization.store_best_weights\n",
    "    best = StoreOptimization.store_best_error\n",
    "    \n",
    "    print(\":: Finished Fold ::\")\n",
    "    model_check = fuzzy_aggregation(tree_shape=tree_shape,current_fold_train=n_fold,ignore_writeClass=False)\n",
    "    acc_output,error_output = model_check.validate_test(best_solution,pos_start,pos_end,show_graph=False)\n",
    "    set_from_train = model_check.evaluate(best_solution,pos_start,pos_end,show_graph=True)\n",
    "\n",
    "    print(\"!! Train error = \",best,\" & Train Acc = \",set_from_train[0],\" & Validate Test = \",error_output[0],\" & Validate accuracy = \",acc_output)\n",
    "    StoreOptimization.static_appendString(\"!! Train error = \"+str(best)+\" Train Acc = \"+str(set_from_train[0])+\" & Validate Test = \"+str(error_output)+\" & Validate accuracy = \"+str(acc_output))\n",
    "    \n",
    "    tn, fp, fn, tp, fuzzy_fitness = set_from_train[1],set_from_train[2],set_from_train[3],set_from_train[4],set_from_train[-1][0]\n",
    "    StoreOptimization.static_appendString(\"Trained tn, fp, fn, tp : %s %s %s %s\" % (tn, fp, fn, tp))\n",
    "    StoreOptimization.static_appendString(\"RMSE Train: %s\" % (set_from_train[-1][1]))\n",
    "    StoreOptimization.static_appendString(\"RMSE Test: %s\" % (error_output[1]))\n",
    "    \n",
    "    if acc_output > acc_cross :\n",
    "        best_sol_cross = best_solution\n",
    "        acc_cross = acc_output\n",
    "        error_cross = error_output[0]\n",
    "        best_fold = n_fold\n",
    "        best_cross_train_err = best\n",
    "        best_acc_train = set_from_train[0]\n",
    "        best_rmse_train = set_from_train[-1][1]\n",
    "        best_rmse_test = error_output[1]\n",
    "        \n",
    "    elif acc_output == acc_cross :\n",
    "        if error_output[0] < error_cross :\n",
    "            best_sol_cross = best_solution\n",
    "            acc_cross = acc_output\n",
    "            error_cross = error_output[0]\n",
    "            best_fold = n_fold\n",
    "\n",
    "            best_cross_train_err = best\n",
    "            best_acc_train = set_from_train[0]\n",
    "            best_rmse_train = set_from_train[-1][1]\n",
    "            best_rmse_test = error_output[1]\n",
    "            \n",
    "    StoreOptimization.static_appendString(\"** Best Weights now = \" + str(best_sol_cross))\n",
    "    StoreOptimization.static_appendString(\"** Best n_Fold now = \" + str(best_fold))\n",
    "    StoreOptimization.static_appendString(\"** Best Train now = \" + str(best_cross_train_err))\n",
    "    StoreOptimization.static_appendString(\"** Best Accuracy Train now = \" + str(best_acc_train))\n",
    "    StoreOptimization.static_appendString(\"** Best RMSE Train now = \" + str(best_rmse_train))\n",
    "    StoreOptimization.static_appendString(\"** Best validation error now = \" + str(error_cross))\n",
    "    StoreOptimization.static_appendString(\"** Best Accuracy Validate now = \" + str(acc_cross))\n",
    "    StoreOptimization.static_appendString(\"** Best RMSE Validate now = \" + str(best_rmse_test))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.697Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're going to train with file ./Final_Data_Train_8_MultiNC.csv & Saved = log_t_f_38s_8Q_SSA_1_fold1.log\n",
      "Y Train count abnormal :  6\n",
      "6 114\n",
      "108 114\n",
      "## parameter weight output class zero [0.2,0.1] \n",
      "## parameter weight output class one [0.1,0.9473684210526316] \n",
      "## New training SSA with n = 3000 , lb = 0 , ub = 1, dimension = 432, iteration = 40, pf= 0.6 with fold = 1 \n",
      "fold 1 best at nFES 1 error 0.04756576809449555 (0,6,0.05263157894736842) rmse 0.2180957773421933\n",
      "fold 1 best at nFES 4 error 0.04756467477189308 (0,6,0.05263157894736842) rmse 0.21809327080837015\n",
      "fold 1 best at nFES 9 error 0.047553560323199615 (108,0,0.9473684210526315) rmse 0.21806778836682786\n",
      "fold 1 best at nFES 22 error 0.047452512295259056 (108,0,0.9473684210526315) rmse 0.21783597566806778\n",
      "fold 1 best at nFES 30 error 0.043809106085638164 (108,0,0.9473684210526315) rmse 0.209306249514051\n",
      "fold 1 best at nFES 169 error 0.033382978023108044 (108,0,0.9473684210526315) rmse 0.18271009283317666\n",
      "fold 1 best at nFES 406 error 0.03247705575258608 (108,0,0.9473684210526315) rmse 0.1802139166451528\n",
      "fold 1 best at nFES 642 error 0.032440524067086404 (108,0,0.9473684210526315) rmse 0.18011253167696695\n",
      "fold 1 nFES 1000 error 0.21809484508721907\n",
      "fold 1 best at nFES 1158 error 0.03165960313446392 (108,0,0.9473684210526315) rmse 0.17793145628152407\n",
      "fold 1 nFES 2000 error 0.21809607779681264\n",
      "fold 1 nFES 3000 error 0.21809624415838436\n",
      "fold 1 nFES 4000 error 0.2155014967543682\n",
      "fold 1 nFES 5000 error 0.21808809144696698\n",
      "fold 1 best at nFES 5100 error 0.03161905318043898 (108,0,0.9473684210526315) rmse 0.1778174715275161\n",
      "fold 1 nFES 6000 error 0.20985166132940491\n",
      "fold 1 nFES 7000 error 0.21796440856608745\n",
      "fold 1 nFES 8000 error 0.21809624415838436\n",
      "fold 1 nFES 9000 error 0.2180962441581471\n",
      "fold 1 nFES 10000 error 0.20306218732954512\n",
      "fold 1 nFES 11000 error 0.21809624415641052\n",
      "fold 1 nFES 12000 error 0.21809624415838275\n",
      "fold 1 nFES 13000 error 0.21809624415838436\n",
      "fold 1 nFES 14000 error 0.21809624336758304\n",
      "fold 1 best at nFES 14256 error 0.031001572449207686 (108,0,0.9473684210526315) rmse 0.1760726340156462\n",
      "fold 1 nFES 15000 error 0.21587418992104435\n",
      "fold 1 nFES 16000 error 0.21809624415838436\n",
      "fold 1 nFES 17000 error 0.21809624415838422\n",
      "fold 1 nFES 18000 error 0.21809624410145026\n",
      "fold 1 nFES 19000 error 0.21488124447800935\n",
      "fold 1 nFES 20000 error 0.21809607025588904\n",
      "fold 1 nFES 21000 error 0.21809458930429287\n",
      "fold 1 nFES 22000 error 0.21809624385815837\n",
      "fold 1 nFES 23000 error 0.21808873611815818\n",
      "fold 1 nFES 24000 error 0.21809410048039185\n",
      "fold 1 nFES 25000 error 0.21809624408736897\n",
      "fold 1 nFES 26000 error 0.21809624415838422\n",
      "fold 1 nFES 27000 error 0.21809624415835493\n",
      "fold 1 nFES 28000 error 0.2170565929741784\n"
     ]
    }
   ],
   "source": [
    "trainWithFold(1,name_file_fold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.701Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loadDataFromPreviousFold(name_file_fold1)\n",
    "trainWithFold(2,name_file_fold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.706Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Joint two files and delete split files\n",
    "'''\n",
    "\n",
    "filenames = [name_file_fold1, name_file_fold2]\n",
    "with open(\"log_t_f_38s_8Q_SSA_\"+getFileNumber()+\".log\", 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "        \n",
    "os.remove(name_file_fold1)\n",
    "os.remove(name_file_fold2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Fold Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.709Z"
    }
   },
   "outputs": [],
   "source": [
    "system_f = fuzzy_aggregation(tree_shape,current_fold_train=best_fold,ignore_writeClass=True).print_results_train(best_sol_cross,pos_start,pos_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.712Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "system_f = fuzzy_aggregation(tree_shape,current_fold_train=best_fold,ignore_writeClass=True).print_results(best_sol_cross,pos_start,pos_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.715Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "system_f = fuzzy_aggregation(tree_shape,ignore_writeClass=True)\n",
    "system_f.set_allWeights(best_sol_cross)\n",
    "system_f.showAllWeights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-28T04:34:12.719Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "str_out = \"training SSA with n = %s , lb = %s , ub = %s, dimension = %s, iteration = %s, pf= %s \" % (train_params[\"NP\"] , train_params[\"lb\"], train_params[\"ub\"], train_params[\"dimension\"], train_params[\"nIteration\"], train_params[\"pf\"])\n",
    "    \n",
    "dt = datetime.now()\n",
    "str_out = \"\\n\"+ dt.strftime(\"%d/%m/%Y %H:%M\") + \" น.\\n\" + str_out\n",
    "    \n",
    "\n",
    "url = \"https://notify-api.line.me/api/notify\"\n",
    "\n",
    "payload = {'message': str_out}\n",
    "files = [\n",
    "\n",
    "]\n",
    "headers = {\n",
    "  'Authorization': 'Bearer bR3qarCoaVfI14aKFkSEOARPU4LMc8ZDfKpUiki1NNl',\n",
    "  'Content-Type': 'multipart/form-data; boundary=--------------------------432408813026345718460603'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, params = payload, files = files)\n",
    "\n",
    "print(response.text.encode('utf8'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 377.85,
   "position": {
    "height": "399.85px",
    "left": "1032px",
    "right": "51px",
    "top": "122px",
    "width": "357px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
