{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:20.912846Z",
     "start_time": "2020-03-05T05:18:20.899836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"notebook_name = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import Javascript\n",
    "Javascript(\"\"\"\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"notebook_name = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:20.977002Z",
     "start_time": "2020-03-05T05:18:20.966216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Fuzzy_Aggregation3-Version92-FullTree-NiaPy\n"
     ]
    }
   ],
   "source": [
    "print(notebook_name)\n",
    "def getFileNumber():\n",
    "    if \"Copy\" not in notebook_name :\n",
    "        return \"1\"\n",
    "    \n",
    "    temp = notebook_name.split(\".\")[0]\n",
    "    temp = temp.split(\"-\")[-1]\n",
    "    temp = temp.replace(\"Copy\",\"\")\n",
    "    return str(int(temp) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:22.867661Z",
     "start_time": "2020-03-05T05:18:21.010134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "#5-3-63\n",
    "#Fix bug\n",
    "#Optimize Compute\n",
    "\n",
    "#reduce start from 10 gen 10 pop reduce from 1 min to ~43 s\n",
    "#Fixef wrong cal fitness\n",
    "\n",
    "\n",
    "#pip install NiaPy==2.0.0rc10\n",
    "\n",
    "#https://grega.xyz/post/niapy_optimize_knn/  \n",
    "%autosave 60\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import bisect\n",
    "import math\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from NiaPy.benchmarks.benchmark import Benchmark\n",
    "\n",
    "#Display graph sequently\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "#set_trace()\n",
    "\n",
    "import random\n",
    "import gc\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:22.900303Z",
     "start_time": "2020-03-05T05:18:22.876856Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert to categorical\n",
    "def to_categorical(val,left_v,right_v) :\n",
    "    if left_v < 0.1 :\n",
    "        left_v = 0.2\n",
    "    if right_v < 0.1 :\n",
    "        right_v = 0.2\n",
    "    output = []\n",
    "    for v in val :\n",
    "        if v < 0.5 :\n",
    "            output.append([left_v,0.1])\n",
    "        else :\n",
    "            output.append([0.1,right_v])\n",
    "    return np.asarray(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:22.937289Z",
     "start_time": "2020-03-05T05:18:22.917995Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred,classes,normalize=False,title=None,cmap=plt.cm.Blues):\n",
    "    y_true = np.asarray(y_true).astype('int')\n",
    "    y_pred = np.asarray(y_pred).astype('int')\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    display.display(fig)\n",
    "    plt.close(fig)\n",
    "#     return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controller to show result of Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:22.967193Z",
     "start_time": "2020-03-05T05:18:22.951007Z"
    }
   },
   "outputs": [],
   "source": [
    "class StoreOptimization(object) :\n",
    "    results = []\n",
    "    generation = 0\n",
    "    \n",
    "    count_generation = 0\n",
    "    \n",
    "    store_best_weights = []\n",
    "    store_best_error = 0\n",
    "    \n",
    "    #default\n",
    "    n_generation_wanted = 1\n",
    "    \n",
    "    store_best_rmse = 1\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def static_N_Gen(val):\n",
    "         StoreOptimization.n_generation_wanted = val\n",
    "    \n",
    "    @staticmethod\n",
    "    def static_clearAll() :\n",
    "        StoreOptimization.generation = 0\n",
    "        StoreOptimization.count_generation = 0\n",
    "        StoreOptimization.store_best_weights = []\n",
    "        StoreOptimization.store_best_error = 100\n",
    "        StoreOptimization.store_best_rmse = 1\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def static_appendString(head_str) :\n",
    "        logging.info('%s' % (head_str))\n",
    "        print('%s' % (head_str))\n",
    "    \n",
    "    @staticmethod\n",
    "    def static_addResult(Pc1,Pc2,Pc,fuzzy_fitness,weights,n_fold,rmse_eval) :\n",
    "        \n",
    "            \n",
    "        StoreOptimization.count_generation = StoreOptimization.count_generation + 1\n",
    "        StoreOptimization.generation = StoreOptimization.generation + 1\n",
    "        \n",
    "        if StoreOptimization.n_generation_wanted == StoreOptimization.count_generation :\n",
    "            StoreOptimization.count_generation = 0\n",
    "            StoreOptimization.static_appendString('fold %s nFES %s error %s' % (n_fold,StoreOptimization.generation, rmse_eval))\n",
    "        \n",
    "        if fuzzy_fitness < StoreOptimization.store_best_error :\n",
    "            StoreOptimization.store_best_error = fuzzy_fitness\n",
    "            StoreOptimization.store_best_weights = weights\n",
    "            StoreOptimization.static_appendString('fold %s best at nFES %s error %s (%s,%s,%s) rmse %s' % (n_fold,StoreOptimization.generation, fuzzy_fitness,Pc1,Pc2,Pc,rmse_eval))\n",
    "            logging.info(weights)\n",
    "\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:22:08.862157Z",
     "start_time": "2020-03-05T05:22:08.847022Z"
    }
   },
   "outputs": [],
   "source": [
    "class leaf_node :\n",
    "    def __init__(self,count_leaves) :\n",
    "        self.list_weight_input = np.ones(count_leaves)\n",
    "        self.gammar_operator = 1.0\n",
    "        \n",
    "    def check_input(self,val) :\n",
    "        '''\n",
    "        Axiom 1\n",
    "        Check input h(0,0,0) = 0\n",
    "        Check input h(1,1,1) = 1\n",
    "        '''\n",
    "        repeat_zeros = np.repeat(0.00000001,len(val))\n",
    "        repeat_ones = np.repeat(0.99999999,len(val))\n",
    "        \n",
    "        if np.sum(val == repeat_zeros) == len(val) :\n",
    "            return np.repeat(0.0,len(val))\n",
    "        \n",
    "        if np.sum(val == repeat_ones) == len(val) :\n",
    "            return np.repeat(1.0,len(val))\n",
    "            \n",
    "        return val\n",
    "        \n",
    "        \n",
    "    def cal_y(self,input_x) :\n",
    "        input_x = self.check_input(input_x)\n",
    "\n",
    "        if len(input_x) != len(self.list_weight_input) :\n",
    "            print(\"Error cal , input not equal weight\")\n",
    "            return\n",
    "\n",
    "        temp_mul_y1 = np.power(input_x, self.list_weight_input)\n",
    "\n",
    "        prod_y1 = np.prod(temp_mul_y1)\n",
    "\n",
    "        y1_out = np.power(prod_y1,1-self.gammar_operator)\n",
    "\n",
    "\n",
    "        temp_mul_y2 = np.power(1-input_x, self.list_weight_input)\n",
    "            \n",
    "        prod_y2 = np.prod(temp_mul_y2)\n",
    "\n",
    "        y2_out = np.power(1 - prod_y2,self.gammar_operator)\n",
    "\n",
    "        real_out = y1_out * y2_out\n",
    "\n",
    "        if real_out == 0 :\n",
    "            real_out = 0.00000001\n",
    "        elif real_out == 1 :\n",
    "            real_out = 0.99999999\n",
    "\n",
    "        return real_out\n",
    "\n",
    "    def change_weights(self,new_weight,new_gammar) :\n",
    "\n",
    "        if self.count_weight() == len(new_weight) :\n",
    "            self.list_weight_input = np.asarray(new_weight)\n",
    "            self.gammar_operator = new_gammar\n",
    "\n",
    "        else :\n",
    "            print(\"Error Update weight!!!!!\")\n",
    "            raise\n",
    "            \n",
    "    def count_weight(self) :\n",
    "        return len(self.list_weight_input)\n",
    "    \n",
    "    def get_weights_gammar(self) :\n",
    "        return self.list_weight_input.tolist() + [self.gammar_operator]\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:23.070289Z",
     "start_time": "2020-03-05T05:18:23.011593Z"
    }
   },
   "outputs": [],
   "source": [
    "class root_tree :\n",
    "    \n",
    "    def __init__(self,list_group) :\n",
    "        self.number_layers = len(list_group)\n",
    "        self.all_nodes = []\n",
    "        \n",
    "\n",
    "        #Leaf (Top) -> Root (Bottom)\n",
    "        \n",
    "        for count_layer in range(0,len(list_group)) :\n",
    "            temp_leaves = []\n",
    "            for count_node in  range(0,len(list_group[count_layer])) :\n",
    "                temp_leaves.append(leaf_node(list_group[count_layer][count_node]))\n",
    "            self.all_nodes.append(temp_leaves)\n",
    "            \n",
    "        #Split vector input to input each group\n",
    "        self.group_input = list_group\n",
    "\n",
    "    \n",
    "    def get_all_weights_wGammar(self) :\n",
    "        #Return weight and gammar all tree to vector\n",
    "        output = []\n",
    "    \n",
    "        for each_layer in self.all_nodes :\n",
    "            for each_node in each_layer :\n",
    "                \n",
    "                #New position vector X\n",
    "                output = output+each_node.get_weights_gammar()\n",
    "            \n",
    "        return output\n",
    "                \n",
    "    def set_all_weights_wGammar(self,new_weights) :\n",
    "        count_weight_idx = 0\n",
    "        \n",
    "        for each_layer in self.all_nodes :\n",
    "            for each_node in each_layer :\n",
    "                \n",
    "                len_weight = each_node.count_weight()\n",
    "                temp_weights = new_weights[count_weight_idx:count_weight_idx + len_weight]\n",
    "                temp_gammar = new_weights[count_weight_idx+len_weight]\n",
    "                \n",
    "                \n",
    "                #Change weights\n",
    "                try : \n",
    "                    each_node.change_weights(temp_weights,temp_gammar)\n",
    "                except :\n",
    "                    print(\"Error change weight !\")\n",
    "                    sys.exit()\n",
    "                \n",
    "                #New position\n",
    "                count_weight_idx = count_weight_idx+len_weight+1\n",
    "        \n",
    "        \n",
    "                \n",
    "          \n",
    "    #For multi objective to find error\n",
    "    def predict_eachLeaf(self,input_X) :\n",
    "        \n",
    "        summation_error = 0\n",
    "        \n",
    "        output_previous_layer = input_X\n",
    "        \n",
    "        summation_resultY = []\n",
    "        \n",
    "        #feed only leaves tree \n",
    "        for idx,each_layer in enumerate(self.all_nodes) :\n",
    "\n",
    "            count_idx = 0\n",
    "            temp_previous_result = []\n",
    "            \n",
    "            if idx != len(self.all_nodes) - 1 :\n",
    "            \n",
    "                for each_node in each_layer :\n",
    "\n",
    "                    input_x_vector = output_previous_layer[count_idx:count_idx + each_node.count_weight()]\n",
    "\n",
    "                    resultFrom_calY = each_node.cal_y(np.asarray(input_x_vector))\n",
    "\n",
    "                    summation_resultY =  summation_resultY + [resultFrom_calY]\n",
    "\n",
    "                    temp_previous_result.append(resultFrom_calY)\n",
    "\n",
    "                    #New position vector X\n",
    "                    count_idx = count_idx+each_node.count_weight()\n",
    "            else :\n",
    "                \n",
    "                #Get old output from previous cal and calculate two output to classify\n",
    "        \n",
    "                temp_output2class = []\n",
    "                for each_node in each_layer :\n",
    "                    input_x_vector = output_previous_layer[0:count_idx + each_node.count_weight()]\n",
    " \n",
    "                    resultFrom_calY = each_node.cal_y(np.asarray(input_x_vector))\n",
    "                    temp_output2class.append(resultFrom_calY)\n",
    "\n",
    "                summation_resultY =  summation_resultY + temp_output2class\n",
    " \n",
    "            output_previous_layer =  temp_previous_result\n",
    "\n",
    "        return summation_resultY\n",
    "    \n",
    "    \n",
    "    #Feed input to get output only\n",
    "    def predict(self,input_X) :\n",
    "        temp = self.predict_eachLeaf(input_X)[-2::1]\n",
    "        if (temp[0] == 0 and temp[1] == 0) or np.isinf(temp[0]) or np.isinf(temp[1]) or np.isnan(temp[0]) or np.isnan(temp[1]) :\n",
    "            temp = self.predict_eachLeaf(input_X)[-2::1]\n",
    "        return temp\n",
    "        \n",
    "    \n",
    "    def readable(self) :\n",
    "        #Return weight and gammar all tree to vector\n",
    "        temp = []\n",
    "        for (idx,each_layer) in enumerate(self.all_nodes) :\n",
    "            temp = []\n",
    "            for (i,each_node) in enumerate(each_layer) :\n",
    "                temp_get_weight = each_node.get_weights_gammar()\n",
    "                print(\"Weight layer \",idx,\":\",i+1,\" \",temp_get_weight[0:-1])\n",
    "                print(\"Gammar operator : \",temp_get_weight[-1])\n",
    "                print(\"Sum Weights : \",np.sum(temp_get_weight[:-1]))\n",
    "                print(\"\")\n",
    "                #Show important weight each group ratios at final step\n",
    "                \n",
    "                temp.append(temp_get_weight)\n",
    "        \n",
    "            print(\"For check sum at layer: \",np.sum([np.sum(x[0:-1]) for x in temp]))\n",
    "            print(\"\")\n",
    "                \n",
    "        print(\"\")\n",
    "        print(\"#### Left output node ####\")\n",
    "        print(\"liquidity ratio : \",temp[0][0])\n",
    "        print(\"Asset utilization or turnover ratio : \",temp[0][1])\n",
    "        print(\"Profitability : \",temp[0][2])\n",
    "        print(\"Asset structure ratios : \",temp[0][3])\n",
    "        print(\"Leverage : \",temp[0][4])\n",
    "        print(\"Growth ratios : \",temp[0][5])\n",
    "        print(\"Gammar operator : \",temp[0][6])\n",
    "        print(\"For check sum : \",np.sum(temp[0]) - temp[0][-1])\n",
    "        print(\"\")\n",
    "        print(\"#### Right output node ####\")\n",
    "        print(\"liquidity ratio : \",temp[1][0])\n",
    "        print(\"Asset utilization or turnover ratio : \",temp[1][1])\n",
    "        print(\"Profitability : \",temp[1][2])\n",
    "        print(\"Asset structure ratios : \",temp[1][3])\n",
    "        print(\"Leverage : \",temp[1][4])\n",
    "        print(\"Growth ratios : \",temp[1][5])\n",
    "        print(\"Gammar operator : \",temp[1][6])\n",
    "        print(\"For check sum : \",np.sum(temp[1])-temp[1][-1])\n",
    "    \n",
    "    def countAllNodesOutput(self) :\n",
    "        output = 0\n",
    "        for count_layer in self.group_input :\n",
    "            output = output + len(count_layer)\n",
    "        return output\n",
    "                \n",
    "\n",
    "    \n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:23.097848Z",
     "start_time": "2020-03-05T05:18:23.075897Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def try_div(x,y):\n",
    "    try: \n",
    "        return x/y\n",
    "    except ZeroDivisionError: \n",
    "        return 0\n",
    "    \n",
    "def swap_weight(val) :\n",
    "    len_weight = len(val)\n",
    "    temp_multiply =  try_div(len_weight,np.sum(val))\n",
    "    if math.isnan(temp_multiply) or temp_multiply == 0 :\n",
    "        temp_multiply = 1\n",
    "        \n",
    "    output = (temp_multiply * np.asarray(val))\n",
    "    output = [0 if math.isnan(x) else x for x in output]\n",
    "\n",
    "    return output\n",
    "    \n",
    "def swap_gammar(val) :\n",
    "    if math.isnan(val) :\n",
    "        return 0\n",
    "    return val\n",
    "\n",
    "# our custom benchmark classs\n",
    "class BenchmarkAllTree(Benchmark):\n",
    "    def __init__(self,tree_shape,start_pos_f,end_pos_f,n_fold):\n",
    "        \n",
    "        self.tree_shape = tree_shape\n",
    "        \n",
    "        self.start_pos_f = start_pos_f\n",
    "        self.end_pos_f = end_pos_f\n",
    "        \n",
    "        self.n_fold = n_fold\n",
    "        \n",
    "        self.fuzzy_system = fuzzy_aggregation(tree_shape = self.tree_shape,current_fold_train=n_fold)\n",
    "        Benchmark.__init__(self, Lower=0, Upper=1)\n",
    "        \n",
    "        \n",
    "    # function which returns evaluate function\n",
    "    def function(self):\n",
    "        def evaluate(D,sol):\n",
    "            gc.collect()\n",
    "            sol = np.abs(sol)\n",
    "\n",
    "            all_weight = []\n",
    "\n",
    "            last_idx = 0\n",
    "\n",
    "\n",
    "            for idx,each_layer in enumerate(self.tree_shape) :\n",
    "                \n",
    "                if idx == len(self.tree_shape) -1 :\n",
    "\n",
    "                        for each_node in each_layer :\n",
    "                            #find weights and gamma before\n",
    "\n",
    "                            len_each_layer_weights = each_node\n",
    "                            len_each_layer_gammas = len(each_layer)\n",
    "\n",
    "                            temp_pos_next_weights = last_idx + len_each_layer_weights\n",
    "\n",
    "\n",
    "                            temp_vector_weights = swap_weight(sol[last_idx:temp_pos_next_weights])\n",
    "                            temp_vector_gammars = sol[temp_pos_next_weights : temp_pos_next_weights + len_each_layer_gammas]\n",
    "\n",
    "                            temp_idx_w = 0\n",
    "                            temp_idx_g = 0\n",
    "                        \n",
    "                        \n",
    "                            all_weight = all_weight + temp_vector_weights[temp_idx_w:temp_idx_w + each_node] + [temp_vector_gammars[temp_idx_g]]\n",
    "                            temp_idx_w = temp_idx_w + each_node\n",
    "                            temp_idx_g = temp_idx_g + 1\n",
    "                            last_idx = last_idx + each_node + 1\n",
    "                    \n",
    "                else :\n",
    "                    #find weights and gamma before\n",
    "                    for each_node in each_layer :\n",
    "                        temp_weights = swap_weight(sol[last_idx:last_idx + each_node])\n",
    "                        temp_gammar = swap_gammar(sol[last_idx + each_node])\n",
    "                        last_idx = last_idx + each_node + 1\n",
    "                        all_weight = all_weight + temp_weights + [temp_gammar]\n",
    "\n",
    "\n",
    "            set_eval = self.fuzzy_system.evaluate(all_weight,self.start_pos_f ,self.end_pos_f)\n",
    "            StoreOptimization.static_addResult(set_eval[1],set_eval[4],set_eval[0],set_eval[-1][0],all_weight,self.n_fold,set_eval[-1][1])\n",
    "\n",
    "            if math.isnan(set_eval[-1][0]) :\n",
    "                set_trace()\n",
    "                \n",
    "\n",
    "            return set_eval[-1][0]\n",
    "        return evaluate\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:23.162343Z",
     "start_time": "2020-03-05T05:18:23.100639Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class fuzzy_aggregation :\n",
    "    def __init__(self,tree_shape, seed=1235,current_fold_train=1,ignore_writeClass=False) :\n",
    "        self.classifier_root_tree = root_tree(tree_shape)\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.current_fold_train = current_fold_train\n",
    "        global crossvalidation\n",
    "        self.crossvalidation = crossvalidation\n",
    "        \n",
    "        global number_feature\n",
    "        self.number_feature = number_feature\n",
    "        self.all_shape = tree_shape \n",
    "        \n",
    "        global all_data_train\n",
    "        self.all_data_train = all_data_train\n",
    "\n",
    "        random.seed(self.seed)\n",
    "        idx = random.sample(range(0, len(self.all_data_train.index)), len(self.all_data_train.index))\n",
    "\n",
    "\n",
    "#         self.data_train,self.data_blindtest = self.split_blind_test(data_train=np.asarray(self.all_data_train)[idx,:])\n",
    "        self.data_train =np.asarray(self.all_data_train)[idx,:]\n",
    "        \n",
    "        temp_X_train,temp_X_test = self.select_fold(self.current_fold_train)\n",
    "        \n",
    "        #Var for used\n",
    "        self.X_train,self.y_train = self.split_features_class(temp_X_train)\n",
    "        self.X_test,self.y_test = self.split_features_class(temp_X_test)\n",
    "        \n",
    "        \n",
    "#         self.X_blindtest,self.y_blindtest = self.split_features_class(self.data_blindtest)\n",
    "\n",
    "        print(\"Y Train count abnormal : \",len(self.y_train[self.y_train == 1]))\n",
    "        print(np.sum(self.y_train==1) ,len(self.y_train))\n",
    "        print(np.sum(self.y_train==0) ,len(self.y_train))\n",
    "        #set wight output\n",
    "        self.weight_classOne = 1 - (np.sum(self.y_train==1) / len(self.y_train))\n",
    "        self.weight_classZero = 1 - (np.sum(self.y_train==0) / len(self.y_train))\n",
    "        \n",
    "       \n",
    "        self.y_real_train_category = to_categorical(self.y_train,self.weight_classZero,self.weight_classOne)\n",
    "        self.y_real_test_category = to_categorical(self.y_test,self.weight_classZero,self.weight_classOne)\n",
    "        \n",
    "        if not ignore_writeClass :\n",
    "            allWeightOutput = to_categorical([0,1],self.weight_classZero,self.weight_classOne)\n",
    "            StoreOptimization.static_appendString(\"## parameter weight output class zero [%s,%s] \" % (allWeightOutput[0][0],allWeightOutput[0][1]))\n",
    "            StoreOptimization.static_appendString(\"## parameter weight output class one [%s,%s] \" % (allWeightOutput[1][0],allWeightOutput[1][1]))\n",
    "            del allWeightOutput\n",
    "        \n",
    "    def split_blind_test(self,test_size=0.8,data_train = []) :\n",
    "    \n",
    "        range_split= math.floor(len(data_train)*test_size)\n",
    "        return data_train[0:range_split,:], data_train[range_split:,:]\n",
    "    \n",
    "    def select_fold(self,number_fold):\n",
    "        #return train,test\n",
    "\n",
    "        range_v = math.floor(len(self.data_train)/self.crossvalidation)\n",
    "        if number_fold == 1 :\n",
    "            return self.data_train[range_v:,:] , self.data_train[0:range_v,:] \n",
    "        elif number_fold == self.crossvalidation :\n",
    "            return self.data_train[0:range_v*(number_fold-1),:], self.data_train[range_v*(number_fold-1):,:] \n",
    "        else :\n",
    "            temp_data_first = self.data_train[0:range_v*(number_fold-1),:]\n",
    "\n",
    "            temp_data_second = self.data_train[range_v*(number_fold):,:]\n",
    "            final_con = np.concatenate((temp_data_first, temp_data_second))\n",
    "            return final_con , self.data_train[range_v*(number_fold-1):range_v*(number_fold),:]\n",
    "    \n",
    "    def split_features_class(self,v_input) :\n",
    "        #Vector feature , Vector class\n",
    "        return v_input[:,0:self.number_feature],v_input[:,-1]\n",
    "    \n",
    "    def calculate_RMSE(self,y_real,y_predict) :\n",
    "        if len(y_predict) != len(y_real) :\n",
    "            print(\"Cannot calculate RMSE\")\n",
    "            sys.exit()\n",
    "\n",
    "        temp_minus = y_real - y_predict\n",
    "        \n",
    "        error_all = np.sum(temp_minus**2,axis=1)/2\n",
    "        \n",
    "        return math.sqrt(np.sum(error_all)/len(error_all))\n",
    "\n",
    "    def predict(self,start_f_in,end_f_in) :\n",
    "       \n",
    "        return [ self.classifier_root_tree.predict( self.X_train[idx,start_f_in:end_f_in+1] ) for idx in range(self.X_train.shape[0]) ]\n",
    "        \n",
    "    '''\n",
    "        Product T-Norm (AND)\n",
    "        Product T-Conorm (OR)\n",
    "        \n",
    "        Min (Max(class1,class2) , Accuracy)\n",
    "        (class_x + class_y - class_x . class_y) . Accuracy\n",
    "        \n",
    "    '''\n",
    "    def fuzzy_fitness_wRMSE(self,y_real,y_real_category,y_predict):\n",
    "        if len(y_predict) != len(y_real_category) :\n",
    "            print(\"Cannot calculate fuzzy fitness\")\n",
    "            sys.exit()\n",
    "\n",
    "        temp_minus = y_real_category - y_predict\n",
    "        \n",
    "        class_1 = np.asarray([])\n",
    "        class_2 =  np.asarray([])\n",
    "\n",
    "        error_all =  np.asarray([])\n",
    "\n",
    "        class_1 = np.sum(temp_minus[np.where(y_real == 0)] ** 2,axis=1)/2\n",
    "        class_2 = np.sum(temp_minus[np.where(y_real == 1)] ** 2,axis=1)/2\n",
    "        error_all = np.sum(temp_minus** 2,axis=1)/2\n",
    "        \n",
    "#         for y,y_r in zip(temp_minus, y_real) :\n",
    "#             if y_r[0] == 1 :\n",
    "#                 class_1.append(np.sum(y**2)/2)\n",
    "#             else :\n",
    "#                 class_2.append(np.sum(y**2)/2)\n",
    "#             error_all.append(np.sum(y**2)/2)\n",
    "\n",
    "        sum_sqrt = np.sqrt(np.sum(error_all)/len(error_all))\n",
    "\n",
    "        sum_class1 = np.sqrt(np.sum(class_1)/len(class_1))\n",
    "\n",
    "        sum_class2 = np.sqrt(np.sum(class_2)/len(class_2))\n",
    "\n",
    "        \n",
    "        return ((sum_class1 +sum_class2 ) - (sum_class1*sum_class2)) * sum_sqrt , sum_sqrt\n",
    "        \n",
    "        \n",
    "    def evaluate(self,weight_gammar,start_f_in,end_f_in,show_graph=False) :\n",
    "        \n",
    "        self.classifier_root_tree.set_all_weights_wGammar(weight_gammar)\n",
    "        y_prediction = np.asarray(self.predict(start_f_in,end_f_in))\n",
    "        \n",
    "        y_binary_prediction = []\n",
    "        for y in y_prediction :\n",
    "            \n",
    "            #[0,1] class 1\n",
    "            if y[0] < y[1] :\n",
    "                y_binary_prediction.append(1)\n",
    "            else :\n",
    "                #[0,1] class 1\n",
    "                y_binary_prediction.append(0)\n",
    "                \n",
    "        #Root mean squared error (RMSE)\n",
    "#         return self.accuracy_cal(self.y_train,y_binary_prediction),self.calculate_RMSE(self.y_train,y_prediction)\n",
    "        tn, fp, fn, tp = confusion_matrix(self.y_train,y_binary_prediction).ravel()\n",
    "        acc_train = self.accuracy_cal(self.y_train,y_binary_prediction,show_graph=show_graph)\n",
    "\n",
    "        return  [acc_train,tn, fp, fn, tp,self.fuzzy_fitness_wRMSE(self.y_train,self.y_real_train_category,y_prediction)]\n",
    "    \n",
    "    def predict_validateTest(self,start_f_in,end_f_in) :\n",
    "        return [ self.classifier_root_tree.predict( self.X_test[idx,start_f_in:end_f_in+1]  ) for idx in range(self.X_test.shape[0]) ]\n",
    "        \n",
    "    \n",
    "    def validate_test(self,weight_gammar,start_f_in,end_f_in,show_graph=False) :\n",
    "        self.classifier_root_tree.set_all_weights_wGammar(weight_gammar)\n",
    "        \n",
    "        y_prediction = np.asarray(self.predict_validateTest(start_f_in,end_f_in))\n",
    "\n",
    "        y_binary_prediction = []\n",
    "        for y in y_prediction :\n",
    "            #[0,1] class 1\n",
    "            if y[0] < y[1] :\n",
    "                y_binary_prediction.append(1)\n",
    "            else :\n",
    "                #[0,1] class 1\n",
    "                y_binary_prediction.append(0)\n",
    "                \n",
    "        return self.accuracy_cal(self.y_test,y_binary_prediction,show_graph=show_graph),self.fuzzy_fitness_wRMSE(self.y_test,self.y_real_test_category,y_prediction)\n",
    "    \n",
    "#     def predict_blindtest(self,start_f_in,end_f_in) :\n",
    "#         return [ self.classifier_root_tree.predict( self.X_blindtest[idx,start_f_in:end_f_in+1]  ) for idx in range(self.X_blindtest.shape[0]) ]\n",
    "        \n",
    "    \n",
    "#     def blind_test(self,weight_gammar,start_f_in,end_f_in) :\n",
    "#         self.classifier_root_tree.set_all_weights_wGammar(weight_gammar)\n",
    "        \n",
    "#         y_prediction = self.predict_blindtest(start_f_in,end_f_in)\n",
    "        \n",
    "#         return self.accuracy_cal(self.y_blindtest,y_prediction),self.calculate_RMSE(self.y_blindtest,y_prediction)\n",
    "    \n",
    "    def calculate_evaluate_model(self,result_wanted_y,y_prediction,y_categorical) :\n",
    "        error_all = []\n",
    "        \n",
    "        y_binary_prediction = []\n",
    "        for (y1,y2) in zip(y_prediction,y_categorical) :\n",
    "            print(\"Predict %s , Actual %s \" % (\"[\" + str( y1[0]) +\",\"+ str(y1[1]) + \"]\",y2))\n",
    "            error_all.append(np.abs(np.sum(y1-y2)/2))\n",
    "            #[1,0] class 0\n",
    "            if  y1[0] < y1[1] :\n",
    "                y_binary_prediction.append(1)\n",
    "            else :\n",
    "                #[0,1] class 1\n",
    "                y_binary_prediction.append(0)\n",
    "            \n",
    "        print(\"MAE = \",np.sum(error_all)/len(error_all))\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(result_wanted_y,y_binary_prediction).ravel()\n",
    "        print(\"\\t-----------\\t \\t-----------\\t\")\n",
    "        print(\"|\\t tn - %s \\t|,|\\t fp - %s \\t|\" % (tn, fp))\n",
    "        print(\"|\\t fn - %s \\t|,|\\t tp - %s \\t|\" % (fn, tp))\n",
    "        print(\"\\t-----------\\t \\t-----------\\t\")\n",
    "        acc = accuracy_score( result_wanted_y,y_binary_prediction)\n",
    "        f1 = self.f1_cal(result_wanted_y, y_binary_prediction)\n",
    "\n",
    "        print(\"Acc = %s , f1 = %s\" % (acc,f1))\n",
    "        print(\"RMSE = \",self.calculate_RMSE(y_categorical,y_prediction))\n",
    "        print(\"Fuzzy Fitness = \",self.fuzzy_fitness_wRMSE(result_wanted_y,y_categorical,y_prediction)[0])\n",
    "        \n",
    "        \n",
    "        plot_confusion_matrix(result_wanted_y, y_binary_prediction,classes = np.asarray(['normal', 'Signed']) )\n",
    "      \n",
    "        \n",
    "    def print_results(self,weight_gammar,start_f_in,end_f_in) :\n",
    "        self.classifier_root_tree.set_all_weights_wGammar(weight_gammar)\n",
    "\n",
    "        #Config\n",
    "        result_wanted_y = self.y_test\n",
    "        result_wanted_X = self.X_test\n",
    "        \n",
    "        y_prediction = np.asarray([ self.classifier_root_tree.predict( result_wanted_X[idx,start_f_in:end_f_in+1]  ) for idx in range(result_wanted_X.shape[0]) ])\n",
    "        \n",
    "        self.calculate_evaluate_model(result_wanted_y,y_prediction,self.y_real_test_category)\n",
    "    \n",
    "    def print_results_train(self,weight_gammar,start_f_in,end_f_in) :\n",
    "        self.classifier_root_tree.set_all_weights_wGammar(weight_gammar)\n",
    "\n",
    "        #Config\n",
    "        result_wanted_y = self.y_train\n",
    "        result_wanted_X = self.X_train\n",
    "        \n",
    "        y_prediction = np.asarray([ self.classifier_root_tree.predict( result_wanted_X[idx,start_f_in:end_f_in+1]  ) for idx in range(result_wanted_X.shape[0]) ])\n",
    "        \n",
    "        self.calculate_evaluate_model(result_wanted_y,y_prediction,self.y_real_train_category)\n",
    "\n",
    "    def set_allWeights(self,new_weight) :\n",
    "        self.classifier_root_tree.set_all_weights_wGammar(new_weight)\n",
    "        \n",
    "    def showAllWeights(self) :\n",
    "        self.classifier_root_tree.readable()\n",
    "    \n",
    "    def accuracy_cal(self,y_real,y_predict,show_graph=False) :\n",
    "        \n",
    "        acc = accuracy_score( y_real,y_predict)\n",
    "        if show_graph == True :\n",
    "            plot_confusion_matrix( y_real,y_predict,classes = np.asarray(['normal', 'Signed']) )\n",
    "        \n",
    "        return acc\n",
    "        \n",
    "    def f1_cal(self,y_real,y_predict) :\n",
    "        f_score = f1_score(y_real,y_predict,average='weighted')\n",
    "        \n",
    "        return f_score\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:23.176157Z",
     "start_time": "2020-03-05T05:18:23.164602Z"
    }
   },
   "outputs": [],
   "source": [
    "# logger = logging.getLogger()\n",
    "# fhandler = logging.FileHandler(filename='log_train_opt.log')\n",
    "# formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "# fhandler.setFormatter(formatter)\n",
    "# logger.addHandler(fhandler)\n",
    "# logger.setLevel(logging.INFO)\n",
    "import datetime \n",
    "class logging(object) :\n",
    "    \n",
    "    file_name = \"log_train_Finan_1.log\"\n",
    "    \n",
    "    def initial(file_name):\n",
    "        logging.file_name = file_name\n",
    "    \n",
    "    @staticmethod\n",
    "    def info(msg) :\n",
    "        f = open(logging.file_name, \"a+\")\n",
    "        f.write(\"%s - %s \\n\" % (datetime.datetime.now(),msg) )\n",
    "        f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:23.185013Z",
     "start_time": "2020-03-05T05:18:23.179086Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFileNameSwarmTrain(val):\n",
    "    if val == 0 :\n",
    "        return \"FP\"\n",
    "    elif val == 1 :\n",
    "        return \"FF\"\n",
    "    elif val == 2 :\n",
    "        return \"GWO\"\n",
    "    elif val == 3 :\n",
    "        return \"CSO\"\n",
    "    else:\n",
    "        return \"MFO\"\n",
    "    \n",
    "    ## 0 - Flower Pollination\n",
    "## 1 - firefly\n",
    "## 2 - GWO\n",
    "## 3 - CSO\n",
    "## 4 - Moth-Flame Optimization (MFO) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:23.207149Z",
     "start_time": "2020-03-05T05:18:23.187511Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "get params from previous fold in case of training not finished\n",
    "'''\n",
    "import ast\n",
    "def loadDataFromPreviousFold(name_previous_fold):\n",
    "    global best_sol_cross, acc_cross, error_cross, best_fold, best_cross_train_err, best_acc_train,best_rmse_train,best_rmse_test\n",
    "\n",
    "    if best_sol_cross != [] :\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        tmp = list(reversed(open(name_previous_fold).readlines()))\n",
    "    except:\n",
    "        print(\"Error cannot continue train from fold 1\")\n",
    "        raise\n",
    "\n",
    "    best_rmse_test = float(tmp[0].rstrip().split(\"** Best RMSE Validate now = \")[1])\n",
    "    acc_cross = float(tmp[1].rstrip().split(\"** Best Accuracy Validate now = \")[1])\n",
    "    error_cross = float(tmp[2].rstrip().split(\"** Best validation error now = \")[1])\n",
    "    best_rmse_train = float(tmp[3].rstrip().split(\"** Best RMSE Train now = \")[1])\n",
    "    best_acc_train = float(tmp[4].rstrip().split(\"** Best Accuracy Train now = \")[1])\n",
    "    best_cross_train_err = float(tmp[5].rstrip().split(\"** Best Train now = \")[1])\n",
    "    best_fold = int(tmp[6].rstrip().split(\"** Best n_Fold now = \")[1])\n",
    "    best_sol_cross = ast.literal_eval(tmp[7].rstrip().split(\"** Best Weights now = \")[1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:18:23.563668Z",
     "start_time": "2020-03-05T05:18:23.209785Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from NiaPy.algorithms.basic import FlowerPollinationAlgorithm\n",
    "from NiaPy.algorithms.basic import FireflyAlgorithm\n",
    "from NiaPy.algorithms.basic import GreyWolfOptimizer\n",
    "from NiaPy.task.task import StoppingTask, OptimizationType\n",
    "\n",
    "def count_weight_from_tree(shape_OfTree):\n",
    "    count_weight = 0\n",
    "    for each_layer in shape_OfTree :\n",
    "        list_all_weight_gammar = [ w + 1 for w in each_layer ]\n",
    "        count_weight = count_weight + np.sum(list_all_weight_gammar)\n",
    "\n",
    "    return count_weight\n",
    "\n",
    "# tree_shape = [[8,8,8,8,8,8,8,8],[2,3,3],[2,1],[2]]\n",
    "#[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4]\n",
    "tree_shape = [[8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8],\n",
    "              [3,2,2,4,4,2,1,4,2,1,2,2,5,1,1,2],\n",
    "              [2,5,3,2,2,2],[6,6]]\n",
    "n_weight_gammar = count_weight_from_tree(tree_shape) \n",
    "\n",
    "try :\n",
    "    name_file_train = \"./Final_Data_Train_8_MultiNC.csv\"\n",
    "    all_data_train = pd.read_csv(name_file_train,index_col=\"index_firm\")\n",
    "except :\n",
    "    name_file_train = \"../Final_Data_Train_8_MultiNC.csv\"\n",
    "    all_data_train = pd.read_csv(name_file_train,index_col=\"index_firm\")\n",
    "    \n",
    "for col in all_data_train.columns[:-1]:\n",
    "    all_data_train[col] = [x if x > 0 else 0.00000001 for x in all_data_train[col]]\n",
    "    all_data_train[col] = [x if x < 1 else 0.99999999 for x in all_data_train[col]]\n",
    "\n",
    "## Arrange columns ##\n",
    "list_ratio = [\"CR\",\"QR\",\"CashR\",\"CA2NA\",\"NWC2TA\"]\n",
    "list_ratio = list_ratio + [\"ART\",\"ACP\",\"ITR\",\"ASP\",\"FA2NW\",\"FAT\",\"NWCTR\",\"TAT\",\"ETR\",\"CA2TR\",\"APT\",\"APP\",\"CC\"]\n",
    "list_ratio = list_ratio + [\"ROA\",\"GPM\",\"NPM\",\"ROE\",\"P2NWC\",\"ROS\",\"OE2NS\"]\n",
    "list_ratio = list_ratio + [\"CA2TA\",\"LA2TA\",\"I2CA\",\"CCE2CA\"]\n",
    "list_ratio = list_ratio + [\"D2TAR\",\"D2E\",\"TL2NW\",\"STD2TD\",\"ICR\",\"RE2S\"]\n",
    "list_ratio = list_ratio + [\"AGR\",\"SGR\",\"NPGR\"]\n",
    "new_name_columns = []\n",
    "for idx , val in enumerate(list_ratio) :\n",
    "    for i in range(0,tree_shape[0][0]) :\n",
    "        new_name_columns.append(list_ratio[idx] + \"-Last\" + str(i))\n",
    "new_name_columns = new_name_columns + [\"class\"]\n",
    "\n",
    "all_data_train = all_data_train[new_name_columns]\n",
    "\n",
    "\n",
    "##### Columns drop #######\n",
    "# columns_drop = []\n",
    "# for ratio in [\"TAT\",\"R2NWC\",\"RE2S\",\"S2NW\",\"emscore\",\"CR\",\"QR\"] :\n",
    "#     for idx in range(0,8) :\n",
    "#         columns_drop = columns_drop + [ratio+\"-Last\"+str(idx)]\n",
    "\n",
    "# all_data_train = all_data_train.drop(columns_drop, axis=1)\n",
    "\n",
    "##################### Store Best fold #########################\n",
    "\n",
    "best_sol_cross = []\n",
    "acc_cross = 0\n",
    "error_cross = 0\n",
    "best_fold = 1\n",
    "best_cross_train_err = 0\n",
    "best_acc_train = 0\n",
    "best_rmse_train = 0\n",
    "best_rmse_test = 0\n",
    "\n",
    "\n",
    "############## Start & End pos feature #######################\n",
    "pos_start = 0\n",
    "pos_end =len(all_data_train.columns)-2\n",
    "\n",
    "\n",
    "\n",
    "################# In Aggregation algor ##################\n",
    "number_feature = pos_end + 1\n",
    "crossvalidation = 2\n",
    "\n",
    "######### Select algorithm to train ############\n",
    "## 0 - Flower Pollination\n",
    "## 1 - firefly\n",
    "## 2 - GWO\n",
    "\n",
    "_select_sw_train = 2\n",
    "\n",
    "\n",
    "\n",
    "############### Config Params ###############\n",
    "\n",
    "train_params = {}\n",
    "train_params[\"NP\"] = 3000\n",
    "n_generations = 40\n",
    "\n",
    "train_params[\"nFES\"] = train_params[\"NP\"] * n_generations\n",
    "train_params[\"dimension\"] = n_weight_gammar\n",
    "\n",
    "\n",
    "######Flower Pollination##########\n",
    "if _select_sw_train == 0 :\n",
    "    train_params[\"p\"] = 0.1\n",
    "\n",
    "\n",
    "########## Firefly algor ##############\n",
    "if _select_sw_train == 1 :\n",
    "    train_params[\"alpha\"] = 1\n",
    "    train_params[\"betamin\"] = 1.5\n",
    "    train_params[\"gamma\"] = 1.5\n",
    "    \n",
    "###### Grey Wolf Optimization ##########\n",
    "if _select_sw_train == 2 :\n",
    "    train_params[\"A_val\"] = 2\n",
    "    train_params[\"C_val\"] = 2\n",
    "\n",
    "\n",
    "# 'D' = D {array} or {int} â€“ Shape of return random numbers \n",
    "name_file_fold1 = \"log_t_f_38s_8Q_NiaPy_\"+getFileNameSwarmTrain(_select_sw_train)+\"_\"+getFileNumber()+\"_fold1.log\"\n",
    "name_file_fold2 = \"log_t_f_38s_8Q_NiaPy_\"+getFileNameSwarmTrain(_select_sw_train)+\"_\"+getFileNumber()+\"_fold2.log\"\n",
    "\n",
    "def trainWithFold(nFold,nameSaveFile) :\n",
    "    global best_sol_cross,acc_cross,error_cross,best_fold,best_cross_train_err,best_acc_train,name_file_train,best_rmse_train,best_rmse_test\n",
    "    \n",
    "    logging.initial(nameSaveFile)\n",
    "    StoreOptimization.static_appendString(\"You're going to train with file \" + name_file_train + \" & Saved = \"+logging.file_name)\n",
    "\n",
    "    n_fold = nFold\n",
    "\n",
    "    #nGEN , nFES\n",
    "    StoreOptimization.static_clearAll()\n",
    "    StoreOptimization.static_N_Gen(1000)\n",
    "\n",
    "    task = StoppingTask(D=train_params[\"dimension\"], nFES=train_params[\"nFES\"], optType=OptimizationType.MINIMIZATION, benchmark=BenchmarkAllTree(tree_shape,pos_start,pos_end,n_fold))\n",
    "\n",
    "    if _select_sw_train == 0 :\n",
    "    #flower pollination\n",
    "        StoreOptimization.static_appendString(\"## New training FP with D=%s,NP = %s, nFES=%s, p=%s, with fold = %s \" % (train_params[\"dimension\"],train_params[\"NP\"], train_params[\"nFES\"], train_params[\"p\"],n_fold))\n",
    "        algorithm = FlowerPollinationAlgorithm(NP = train_params[\"NP\"], p=train_params[\"p\"])\n",
    "\n",
    "    if _select_sw_train == 1 :\n",
    "    #firefly\n",
    "        StoreOptimization.static_appendString(\"## New training FF with D=%s,NP = %s, nFES=%s, alpha=%s, betamin=%s, gamma = %s with fold = %s \" % (train_params[\"dimension\"],train_params[\"NP\"], train_params[\"nFES\"], train_params[\"alpha\"],train_params[\"betamin\"],train_params[\"gamma\"] ,n_fold))\n",
    "        algorithm = FireflyAlgorithm(NP = train_params[\"NP\"], alpha=train_params[\"alpha\"], betamin=train_params[\"betamin\"], gamma=train_params[\"gamma\"])\n",
    "\n",
    "\n",
    "    #GWO\n",
    "    if _select_sw_train == 2 :\n",
    "        StoreOptimization.static_appendString(\"## New training GWO with D=%s,NP = %s, nFES=%s, A = %s, C = %s with fold = %s \" % (train_params[\"dimension\"],train_params[\"NP\"], train_params[\"nFES\"],train_params[\"A_val\"],train_params[\"C_val\"] ,n_fold))\n",
    "        algorithm = GreyWolfOptimizer(NP=train_params[\"NP\"])\n",
    "\n",
    "\n",
    "    try:\n",
    "        best = algorithm.run(task=task)\n",
    "    except Exception as e:\n",
    "        set_trace()\n",
    "        print(\"error\",e)\n",
    "    print(\"Optimal Weight and Gammar are : \")  \n",
    "    if best[1] != StoreOptimization.store_best_error :\n",
    "        set_trace()\n",
    "        print(\"Best not equal we find\")\n",
    "        \n",
    "    best_solution = StoreOptimization.store_best_weights\n",
    "    best = StoreOptimization.store_best_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\":: Finished Fold ::\")\n",
    "    model_check = fuzzy_aggregation(tree_shape=tree_shape,current_fold_train=n_fold,ignore_writeClass=False)\n",
    "    acc_output,error_output = model_check.validate_test(best_solution,pos_start,pos_end,show_graph=False)\n",
    "    set_from_train = model_check.evaluate(best_solution,pos_start,pos_end,show_graph=True)\n",
    "\n",
    "    print(\"!! Train error = \",best,\" & Train Acc = \",set_from_train[0],\" & Validate Test = \",error_output[0],\" & Validate accuracy = \",acc_output)\n",
    "    StoreOptimization.static_appendString(\"!! Train error = \"+str(best)+\" Train Acc = \"+str(set_from_train[0])+\" & Validate Test = \"+str(error_output)+\" & Validate accuracy = \"+str(acc_output))\n",
    "    \n",
    "    tn, fp, fn, tp, fuzzy_fitness = set_from_train[1],set_from_train[2],set_from_train[3],set_from_train[4],set_from_train[-1][0]\n",
    "    StoreOptimization.static_appendString(\"Trained tn, fp, fn, tp : %s %s %s %s\" % (tn, fp, fn, tp))\n",
    "    StoreOptimization.static_appendString(\"RMSE Train: %s\" % (set_from_train[-1][1]))\n",
    "    StoreOptimization.static_appendString(\"RMSE Test: %s\" % (error_output[1]))\n",
    "    \n",
    "    if acc_output > acc_cross :\n",
    "        best_sol_cross = best_solution\n",
    "        acc_cross = acc_output\n",
    "        error_cross = error_output[0]\n",
    "        best_fold = n_fold\n",
    "        best_cross_train_err = best\n",
    "        best_acc_train = set_from_train[0]\n",
    "        best_rmse_train = set_from_train[-1][1]\n",
    "        best_rmse_test = error_output[1]\n",
    "        \n",
    "    elif acc_output == acc_cross :\n",
    "        if error_output[0] < error_cross :\n",
    "            best_sol_cross = best_solution\n",
    "            acc_cross = acc_output\n",
    "            error_cross = error_output[0]\n",
    "            best_fold = n_fold\n",
    "\n",
    "            best_cross_train_err = best\n",
    "            best_acc_train = set_from_train[0]\n",
    "            best_rmse_train = set_from_train[-1][1]\n",
    "            best_rmse_test = error_output[1]\n",
    "            \n",
    "    StoreOptimization.static_appendString(\"** Best Weights now = \" + str(best_sol_cross))\n",
    "    StoreOptimization.static_appendString(\"** Best n_Fold now = \" + str(best_fold))\n",
    "    StoreOptimization.static_appendString(\"** Best Train now = \" + str(best_cross_train_err))\n",
    "    StoreOptimization.static_appendString(\"** Best Accuracy Train now = \" + str(best_acc_train))\n",
    "    StoreOptimization.static_appendString(\"** Best RMSE Train now = \" + str(best_rmse_train))\n",
    "    StoreOptimization.static_appendString(\"** Best validation error now = \" + str(error_cross))\n",
    "    StoreOptimization.static_appendString(\"** Best Accuracy Validate now = \" + str(acc_cross))\n",
    "    StoreOptimization.static_appendString(\"** Best RMSE Validate now = \" + str(best_rmse_test))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T10:23:16.428499Z",
     "start_time": "2020-03-01T10:22:23.660073Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainWithFold(1,name_file_fold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T10:19:04.924324Z",
     "start_time": "2020-03-01T10:18:19.515661Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loadDataFromPreviousFold(name_file_fold1)\n",
    "trainWithFold(2,name_file_fold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T10:19:04.974218Z",
     "start_time": "2020-03-01T10:19:04.931590Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Joint two files and delete split files\n",
    "'''\n",
    "\n",
    "filenames = [name_file_fold1, name_file_fold2]\n",
    "with open(\"log_t_f_38s_8Q_NiaPy_\"+getFileNameSwarmTrain(_select_sw_train)+\"_\"+getFileNumber()+\".log\", 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "        \n",
    "os.remove(name_file_fold1)\n",
    "os.remove(name_file_fold2)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Fold Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T10:19:06.228363Z",
     "start_time": "2020-03-01T10:19:05.012449Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "system_f = fuzzy_aggregation(tree_shape,current_fold_train=best_fold,ignore_writeClass=True).print_results_train(best_sol_cross,pos_start,pos_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T10:19:07.278648Z",
     "start_time": "2020-03-01T10:19:06.247271Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "system_f = fuzzy_aggregation(tree_shape,current_fold_train=best_fold,ignore_writeClass=True).print_results(best_sol_cross,pos_start,pos_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T05:22:12.247674Z",
     "start_time": "2020-03-05T05:22:12.167783Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Train count abnormal :  6\n",
      "6 114\n",
      "108 114\n",
      "Weight layer  0 : 1   [0.21050739845711722, 1.5926981379317722, 2.4740574518722354, 0.0033555928017144424, 0.030115228161876336, 0.47962824806205556, 0.4545584315765359, 2.7550795111366946]\n",
      "Gammar operator :  0.047136043549431246\n",
      "Sum Weights :  8.000000000000002\n",
      "\n",
      "Weight layer  0 : 2   [0.05146269660115091, 0.2909073974733768, 3.4761815694348615, 0.03579297688474312, 0.870676710131503, 2.9913319026379335, 0.09127548156687254, 0.19237126526955892]\n",
      "Gammar operator :  0.32057538181649564\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 3   [0.661742004111523, 1.0736052324252112, 1.0094523765634404, 0.262810145155096, 1.5827917838773848, 1.541632989698784, 1.0308198705449743, 0.8371455976235855]\n",
      "Gammar operator :  0.2295340499156818\n",
      "Sum Weights :  7.999999999999999\n",
      "\n",
      "Weight layer  0 : 4   [0.5394505853487107, 2.4688902189804547, 1.4980981500122277, 0.1276377564207464, 0.6178013269960175, 2.2993417882242277, 0.447988604382681, 0.000791569634933645]\n",
      "Gammar operator :  0.22660718445690545\n",
      "Sum Weights :  7.999999999999999\n",
      "\n",
      "Weight layer  0 : 5   [2.0241588234849814, 1.386288440279584, 0.29755832144447797, 0.41935489329321185, 0.7728315130411335, 0.559944173148329, 0.04115056696683546, 2.4987132683414472]\n",
      "Gammar operator :  0.024771352607438624\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 6   [0.00932071085670527, 1.0431020019273611, 0.3683920335948712, 0.019935887512586938, 1.7382625526953979, 0.43022094059602, 2.0864749183141003, 2.3042909545029566]\n",
      "Gammar operator :  0.4790875019702174\n",
      "Sum Weights :  7.999999999999999\n",
      "\n",
      "Weight layer  0 : 7   [2.436932918666177, 0.5430742655529219, 0.510092555932315, 0.8643258052948939, 0.11824341216702904, 1.7025869865978112, 1.0024097736855069, 0.8223342821033445]\n",
      "Gammar operator :  0.06947307522556719\n",
      "Sum Weights :  7.999999999999999\n",
      "\n",
      "Weight layer  0 : 8   [1.4519362869603234, 1.8521338024176774, 0.24492042823892932, 2.328347829942674, 0.6312574339018693, 0.5952197820510294, 0.2255563324882278, 0.6706281039992683]\n",
      "Gammar operator :  0.23505184427461043\n",
      "Sum Weights :  7.999999999999999\n",
      "\n",
      "Weight layer  0 : 9   [0.24027447910470698, 0.2766148383637666, 0.03882639915111635, 0.2463098580081359, 0.8219386885053939, 3.579828575899401, 2.203070959414168, 0.5931362015533118]\n",
      "Gammar operator :  0.010318251882581475\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 10   [0.9135835269697336, 0.8351239933349842, 0.6235999238142166, 1.1933755632799505, 2.450158301906782, 1.5676462886916633, 0.07803173707033653, 0.3384806649323321]\n",
      "Gammar operator :  0.14587095433979855\n",
      "Sum Weights :  7.999999999999998\n",
      "\n",
      "Weight layer  0 : 11   [0.4888904545150831, 1.655392252926092, 0.8150409152585817, 0.43902631564685, 1.6478896282545616, 0.5324363110819956, 2.386314312812737, 0.03500980950409785]\n",
      "Gammar operator :  0.7453084482340734\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 12   [1.1814836435906109, 1.2498687748440913, 0.2829963339515157, 0.606701964922307, 1.0944594122702778, 2.3287637288230885, 0.4406436735053465, 0.815082468092763]\n",
      "Gammar operator :  0.6057631185137674\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 13   [0.20373865325646084, 1.8650447012482034, 0.24925001301466357, 1.91915733693965, 0.9572816036501819, 0.7112144780801165, 0.6006486916632714, 1.4936645221474516]\n",
      "Gammar operator :  0.1662544771785903\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 14   [1.7768452087282112, 1.1653327216125136, 0.16724324904017748, 0.866956424679283, 0.8703331543929054, 0.8506382594065177, 1.3231896161841543, 0.9794613659562388]\n",
      "Gammar operator :  0.04233614668227422\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 15   [0.45596265823683746, 1.1554544772721302, 0.5320429051412683, 1.8550790484859825, 0.31515548784559994, 0.12214351342606229, 1.1067286315413347, 2.457433278050785]\n",
      "Gammar operator :  0.20875004655606047\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 16   [3.12328522672934, 0.007331791754365511, 0.2527121289777974, 1.5074169921458542, 0.9742662066558369, 0.4506663922025594, 0.05052216507525074, 1.6337990964589968]\n",
      "Gammar operator :  0.13064819022246962\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 17   [1.9960001575304307, 0.5643172575149065, 1.8307459272157691, 1.1844211258259563, 0.4939445965684389, 0.5631223013945028, 0.8305515732646702, 0.5368970606853267]\n",
      "Gammar operator :  0.1652048696105164\n",
      "Sum Weights :  8.000000000000002\n",
      "\n",
      "Weight layer  0 : 18   [0.9278049895348212, 1.0524173665900076, 2.756515084441767, 0.6103688046090974, 0.5927818283481101, 0.7471221745016005, 1.305958320657012, 0.0070314313175834945]\n",
      "Gammar operator :  0.1980557583049493\n",
      "Sum Weights :  7.999999999999999\n",
      "\n",
      "Weight layer  0 : 19   [0.22634839019144432, 2.3004571153374087, 1.4182895950887842, 0.17739945803383053, 0.03235254191878522, 1.2852629487658287, 0.45855752890621, 2.101332421757709]\n",
      "Gammar operator :  0.27874721701095845\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 20   [1.6950715419065552, 1.008213172248025, 0.38608547538104454, 0.00025299495613844434, 0.9303936472749119, 0.7779332310850458, 1.9571355220619389, 1.2449144150863414]\n",
      "Gammar operator :  0.23683970778017885\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 21   [0.5911559610237533, 1.7766123541680339, 0.10071294278853231, 0.3282382453087408, 1.4940878363046486, 1.7960468158115397, 1.3143732457333173, 0.5987725988614341]\n",
      "Gammar operator :  0.4614966866980262\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 22   [1.0797039693069657, 1.8318667885272526, 1.1212667225335005, 2.0588918583275566, 0.4044078005111775, 0.7272343955304282, 0.5625494786837371, 0.2140789865793813]\n",
      "Gammar operator :  0.044632066048245066\n",
      "Sum Weights :  7.999999999999999\n",
      "\n",
      "Weight layer  0 : 23   [0.41030982388696485, 2.457111318120001, 0.9308401032721415, 0.7162296899658718, 2.5549319146528022, 0.19109558619213118, 0.3200813029958745, 0.4194002609142129]\n",
      "Gammar operator :  0.3158254281445139\n",
      "Sum Weights :  7.999999999999999\n",
      "\n",
      "Weight layer  0 : 24   [1.0314975154079356, 2.316700439797321, 0.5502633685391009, 1.6571373152479842, 0.09809577137938592, 0.5971062898133923, 1.2082190961254298, 0.5409802036894502]\n",
      "Gammar operator :  0.11665809841693418\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 25   [2.2422531748486727, 0.2900098666516995, 0.5145041379148534, 0.20713025316571557, 0.13134223296549008, 1.5906933224718436, 1.1650118131403626, 1.8590551988413617]\n",
      "Gammar operator :  0.0055268169694598565\n",
      "Sum Weights :  7.999999999999999\n",
      "\n",
      "Weight layer  0 : 26   [1.9442341208148908, 0.24300036694713473, 0.05787786845876841, 0.8305438550325059, 1.5328788521513739, 2.1149068374874487, 0.6750300134962076, 0.6015280856116705]\n",
      "Gammar operator :  0.0545994054540345\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 27   [0.2326810717549827, 0.18846694891470456, 2.4828220225539, 0.7191324935364612, 0.13470622638376792, 1.442170869501888, 2.155239291408822, 0.6447810759454732]\n",
      "Gammar operator :  0.38660022412503015\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 28   [1.0000739489469226, 1.9174349321584803, 1.721694565088806, 0.6934399629960825, 0.1198393779617103, 0.2548920345338076, 1.7213862504910233, 0.5712389278231677]\n",
      "Gammar operator :  0.03781943992382627\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 29   [0.05213575759816153, 0.24718863092123333, 0.5833679224071803, 0.0024052084459864425, 0.7998930913514746, 2.060880146771443, 2.3912311711516137, 1.8628980713529084]\n",
      "Gammar operator :  0.9593743316450966\n",
      "Sum Weights :  8.000000000000002\n",
      "\n",
      "Weight layer  0 : 30   [0.2775831203686719, 0.3591958266324527, 1.8763460175068827, 0.20351621897827013, 1.7457634954420844, 1.5677961761834074, 0.8964242944508758, 1.0733748504373541]\n",
      "Gammar operator :  0.3901847877322919\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 31   [1.6334623381782316, 3.0302920811093883, 0.6944391341972521, 1.3688267609245284, 0.13160262650012478, 0.148131539987582, 0.38219707919327084, 0.6110484399096214]\n",
      "Gammar operator :  0.05202972588156949\n",
      "Sum Weights :  7.999999999999999\n",
      "\n",
      "Weight layer  0 : 32   [2.7137541267146927, 1.1269969843631675, 1.6963848808020483, 0.10647904055682769, 1.3518274592700579, 0.48229875384385634, 0.3084804583520086, 0.21377829609734222]\n",
      "Gammar operator :  0.2703520379769966\n",
      "Sum Weights :  8.000000000000002\n",
      "\n",
      "Weight layer  0 : 33   [0.8325039058347047, 0.634178458649559, 0.9824648137024579, 0.05205735782561077, 2.1310958980002614, 0.2681069560625306, 1.0100736736588745, 2.089518936266001]\n",
      "Gammar operator :  0.2490045698125006\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 34   [1.7758449179588036, 0.9895587265876638, 1.3888430196148183, 0.8776064060960519, 0.8131815286742006, 0.5476623449842648, 0.2993427070854486, 1.3079603489987486]\n",
      "Gammar operator :  0.02825088431319242\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 35   [0.9377932813832912, 0.8799687346295951, 3.145162036228894, 0.8097261982051815, 0.30930782179155775, 0.2298027026537501, 0.9768142454173081, 0.7114249796904225]\n",
      "Gammar operator :  0.435396877249351\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 36   [0.805701843137679, 0.8089684844440513, 0.42321728066831055, 1.3871556795865616, 1.162592274844155, 2.0226888080251526, 1.2022295183009082, 0.18744611099318065]\n",
      "Gammar operator :  0.18198668961260067\n",
      "Sum Weights :  8.0\n",
      "\n",
      "Weight layer  0 : 37   [1.8918245648670504, 0.3616836268377107, 0.19228498069134858, 1.304326314686869, 1.0993447311891522, 0.5592741861737219, 2.450028450809966, 0.14123314474418247]\n",
      "Gammar operator :  0.9588885927356771\n",
      "Sum Weights :  8.000000000000002\n",
      "\n",
      "Weight layer  0 : 38   [1.4787492623582352, 0.78471488352048, 0.7773499211436439, 1.3743722748592615, 0.2002010618247708, 2.2369674251123515, 0.7719827375593943, 0.37566243362186386]\n",
      "Gammar operator :  0.9991271729532993\n",
      "Sum Weights :  8.0\n",
      "\n",
      "For check sum at layer:  304.0\n",
      "\n",
      "Weight layer  1 : 1   [0.33056557117264795, 1.221573405873195, 1.447861022954157]\n",
      "Gammar operator :  0.202845724281555\n",
      "Sum Weights :  3.0\n",
      "\n",
      "Weight layer  1 : 2   [0.34595654693086086, 1.654043453069139]\n",
      "Gammar operator :  0.14677562986591536\n",
      "Sum Weights :  2.0\n",
      "\n",
      "Weight layer  1 : 3   [1.327447037725013, 0.672552962274987]\n",
      "Gammar operator :  0.8958692326912638\n",
      "Sum Weights :  2.0\n",
      "\n",
      "Weight layer  1 : 4   [1.13406829340515, 2.1882223748882725, 0.47515733909512836, 0.20255199261144882]\n",
      "Gammar operator :  0.3928393773890689\n",
      "Sum Weights :  3.9999999999999996\n",
      "\n",
      "Weight layer  1 : 5   [1.0501437906397737, 0.004483225343623742, 0.8911477595131567, 2.0542252245034454]\n",
      "Gammar operator :  0.14718253014008895\n",
      "Sum Weights :  3.9999999999999996\n",
      "\n",
      "Weight layer  1 : 6   [0.34150545420900086, 1.658494545790999]\n",
      "Gammar operator :  0.9779931678605505\n",
      "Sum Weights :  1.9999999999999998\n",
      "\n",
      "Weight layer  1 : 7   [1.0]\n",
      "Gammar operator :  0.550592047157522\n",
      "Sum Weights :  1.0\n",
      "\n",
      "Weight layer  1 : 8   [0.5276004316665621, 0.07017956684432558, 1.6335304754249256, 1.7686895260641866]\n",
      "Gammar operator :  0.24706817083496802\n",
      "Sum Weights :  4.0\n",
      "\n",
      "Weight layer  1 : 9   [0.8795379141215423, 1.1204620858784577]\n",
      "Gammar operator :  0.5116917548891703\n",
      "Sum Weights :  2.0\n",
      "\n",
      "Weight layer  1 : 10   [1.0]\n",
      "Gammar operator :  0.285575926560881\n",
      "Sum Weights :  1.0\n",
      "\n",
      "Weight layer  1 : 11   [0.2177348917926985, 1.7822651082073013]\n",
      "Gammar operator :  0.7205165129387313\n",
      "Sum Weights :  1.9999999999999998\n",
      "\n",
      "Weight layer  1 : 12   [1.9551759090578116, 0.044824090942188595]\n",
      "Gammar operator :  0.26668432932196245\n",
      "Sum Weights :  2.0\n",
      "\n",
      "Weight layer  1 : 13   [0.3148589007306852, 0.4629808006479015, 2.896921057709581, 1.249208354428479, 0.07603088648335408]\n",
      "Gammar operator :  0.027300957823199884\n",
      "Sum Weights :  5.0\n",
      "\n",
      "Weight layer  1 : 14   [1.0]\n",
      "Gammar operator :  0.8932554842346314\n",
      "Sum Weights :  1.0\n",
      "\n",
      "Weight layer  1 : 15   [1.0]\n",
      "Gammar operator :  0.37063877211055324\n",
      "Sum Weights :  1.0\n",
      "\n",
      "Weight layer  1 : 16   [0.33443879655904607, 1.6655612034409542]\n",
      "Gammar operator :  0.6544979991851269\n",
      "Sum Weights :  2.0\n",
      "\n",
      "For check sum at layer:  38.0\n",
      "\n",
      "Weight layer  2 : 1   [1.4646545315588244, 0.5353454684411755]\n",
      "Gammar operator :  0.22959852526749114\n",
      "Sum Weights :  2.0\n",
      "\n",
      "Weight layer  2 : 2   [0.22835652209410515, 0.19338604307126475, 2.705593500638585, 0.9146909185492426, 0.9579730156468022]\n",
      "Gammar operator :  0.17597598190822783\n",
      "Sum Weights :  4.999999999999999\n",
      "\n",
      "Weight layer  2 : 3   [1.1025921201871576, 1.38713648980931, 0.5102713900035328]\n",
      "Gammar operator :  0.02031095851667591\n",
      "Sum Weights :  3.0000000000000004\n",
      "\n",
      "Weight layer  2 : 4   [1.7976523687627946, 0.20234763123720523]\n",
      "Gammar operator :  0.7133153361458143\n",
      "Sum Weights :  1.9999999999999998\n",
      "\n",
      "Weight layer  2 : 5   [0.4910394227355467, 1.5089605772644534]\n",
      "Gammar operator :  0.021996460554463273\n",
      "Sum Weights :  2.0\n",
      "\n",
      "Weight layer  2 : 6   [1.8623929080172426, 0.1376070919827574]\n",
      "Gammar operator :  1.0\n",
      "Sum Weights :  2.0\n",
      "\n",
      "For check sum at layer:  16.0\n",
      "\n",
      "Weight layer  3 : 1   [1.091503571106194, 2.3064805603048457, 1.4689857518282612, 0.35326005988964093, 0.23209060268189294, 0.5476794541891649]\n",
      "Gammar operator :  1.0\n",
      "Sum Weights :  6.0\n",
      "\n",
      "Weight layer  3 : 2   [0.20369887789457036, 0.23879315851662264, 0.8874256828957529, 3.9511667276458846, 0.38882291972368715, 0.330092633323483]\n",
      "Gammar operator :  1.0\n",
      "Sum Weights :  6.0\n",
      "\n",
      "For check sum at layer:  12.0\n",
      "\n",
      "\n",
      "#### Left output node ####\n",
      "liquidity ratio :  1.091503571106194\n",
      "Asset utilization or turnover ratio :  2.3064805603048457\n",
      "Profitability :  1.4689857518282612\n",
      "Asset structure ratios :  0.35326005988964093\n",
      "Leverage :  0.23209060268189294\n",
      "Growth ratios :  0.5476794541891649\n",
      "Gammar operator :  1.0\n",
      "For check sum :  6.0\n",
      "\n",
      "#### Right output node ####\n",
      "liquidity ratio :  0.20369887789457036\n",
      "Asset utilization or turnover ratio :  0.23879315851662264\n",
      "Profitability :  0.8874256828957529\n",
      "Asset structure ratios :  3.9511667276458846\n",
      "Leverage :  0.38882291972368715\n",
      "Growth ratios :  0.330092633323483\n",
      "Gammar operator :  1.0\n",
      "For check sum :  6.0\n"
     ]
    }
   ],
   "source": [
    "system_f = fuzzy_aggregation(tree_shape,ignore_writeClass=True)\n",
    "system_f.set_allWeights(best_sol_cross)\n",
    "system_f.showAllWeights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Mail Finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:53:01.562440Z",
     "start_time": "2020-03-04T10:52:56.621215Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if _select_sw_train == 0 :\n",
    "#flower pollination\n",
    "    str_out = \"training FP with D=%s,NP = %s, nFES=%s, p=%s \" % (train_params[\"dimension\"],train_params[\"NP\"], train_params[\"nFES\"], train_params[\"p\"])\n",
    "\n",
    "if _select_sw_train == 1 :\n",
    "#firefly\n",
    "    str_out = \"training FF with D=%s,NP = %s, nFES=%s, alpha=%s, betamin=%s, gamma = %s \" % (train_params[\"dimension\"],train_params[\"NP\"], train_params[\"nFES\"], train_params[\"alpha\"],train_params[\"betamin\"],train_params[\"gamma\"])\n",
    "\n",
    "\n",
    "#GWO\n",
    "if _select_sw_train == 2 :\n",
    "    str_out = \"training GWO with D=%s,NP = %s, nFES=%s, A = %s, C = %s  \" % (train_params[\"dimension\"],train_params[\"NP\"], train_params[\"nFES\"],train_params[\"A_val\"],train_params[\"C_val\"] )\n",
    "\n",
    "dt = datetime.datetime.now()\n",
    "str_out = \"\\n\"+ dt.strftime(\"%d/%m/%Y %H:%M\") + \" à¸™.\\n\" + str_out\n",
    "    \n",
    "\n",
    "url = \"https://notify-api.line.me/api/notify\"\n",
    "\n",
    "payload = {'message': str_out}\n",
    "files = [\n",
    "\n",
    "]\n",
    "headers = {\n",
    "  'Authorization': 'Bearer bR3qarCoaVfI14aKFkSEOARPU4LMc8ZDfKpUiki1NNl',\n",
    "  'Content-Type': 'multipart/form-data; boundary=--------------------------432408813026345718460603'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, params = payload, files = files)\n",
    "\n",
    "print(response.text.encode('utf8'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "453px",
    "width": "168px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 377.85,
   "position": {
    "height": "503.85px",
    "left": "298px",
    "right": "51px",
    "top": "300px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
